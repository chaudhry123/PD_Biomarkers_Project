{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'matthews_corrcoef', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'positive_likelihood_ratio', 'neg_negative_likelihood_ratio', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pyreadr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import sklearn\n",
    "\n",
    "\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyreadr.read_r('/Users/fayzan/PycharmProjects/PGS/Data/df10.rds')\n",
    "df = data[None]\n",
    "df.rename(columns = {'X21022.0.0':'Age'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid_correct</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>EID</th>\n",
       "      <th>Genotyping Array</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Plate.Name</th>\n",
       "      <th>Well</th>\n",
       "      <th>Cluster.CR</th>\n",
       "      <th>dQC</th>\n",
       "      <th>Internal.Pico</th>\n",
       "      <th>...</th>\n",
       "      <th>X21.38740824_A_G_G</th>\n",
       "      <th>X21.39972727_C_A_A</th>\n",
       "      <th>X21.44357419_T_G_T</th>\n",
       "      <th>X22.22599537_G_A_A</th>\n",
       "      <th>X22.29656431_C_T_T</th>\n",
       "      <th>X22.39738425_A_C_A</th>\n",
       "      <th>X22.39738501_G_C_G</th>\n",
       "      <th>X22.39743170_G_T_G</th>\n",
       "      <th>X22.39758541_A_G_A</th>\n",
       "      <th>X22.39758881_A_G_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000013</td>\n",
       "      <td>A550484-4256924-081516-126_D01</td>\n",
       "      <td>1000013</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b085</td>\n",
       "      <td>SMP4_0014675A</td>\n",
       "      <td>D01</td>\n",
       "      <td>99.791</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>38.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000024</td>\n",
       "      <td>A550465-4195810-090314-853_G11</td>\n",
       "      <td>1000024</td>\n",
       "      <td>UKBL</td>\n",
       "      <td>UKBiLEVEAX_b10</td>\n",
       "      <td>SMP4_0008989</td>\n",
       "      <td>G11</td>\n",
       "      <td>99.144</td>\n",
       "      <td>0.98328</td>\n",
       "      <td>42.4077</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000048</td>\n",
       "      <td>A550484-4256917-081316-053_H04</td>\n",
       "      <td>1000048</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b086</td>\n",
       "      <td>SMP4_0015928A</td>\n",
       "      <td>H04</td>\n",
       "      <td>99.800</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>33.7400</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000055</td>\n",
       "      <td>A550484-4256305-080616-828_F03</td>\n",
       "      <td>1000055</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b090</td>\n",
       "      <td>SMP4_0012484A</td>\n",
       "      <td>F03</td>\n",
       "      <td>99.750</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>40.3500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000067</td>\n",
       "      <td>A550484-4255254-072116-313_E08</td>\n",
       "      <td>1000067</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b084</td>\n",
       "      <td>SMP4_0009406A</td>\n",
       "      <td>E08</td>\n",
       "      <td>99.007</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>29.0900</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408410</th>\n",
       "      <td>6025313</td>\n",
       "      <td>A550484-4256928-081616-316_A08</td>\n",
       "      <td>6025313</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b085</td>\n",
       "      <td>SMP4_0015885A</td>\n",
       "      <td>A08</td>\n",
       "      <td>99.730</td>\n",
       "      <td>0.99000</td>\n",
       "      <td>32.7300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408411</th>\n",
       "      <td>6025324</td>\n",
       "      <td>A550484-4248959-050516-528_B08</td>\n",
       "      <td>6025324</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b073</td>\n",
       "      <td>SMP4_0010000A</td>\n",
       "      <td>B08</td>\n",
       "      <td>99.482</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>21.3100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408412</th>\n",
       "      <td>6025348</td>\n",
       "      <td>A550484-4261892-101716-410_A05</td>\n",
       "      <td>6025348</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b094</td>\n",
       "      <td>SMP4_0018028A</td>\n",
       "      <td>A05</td>\n",
       "      <td>99.708</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>39.1300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408413</th>\n",
       "      <td>6025355</td>\n",
       "      <td>A550484-4245646-040516-701_G07</td>\n",
       "      <td>6025355</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b062</td>\n",
       "      <td>SMP4_0012176B</td>\n",
       "      <td>G07</td>\n",
       "      <td>99.792</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>20.8300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408414</th>\n",
       "      <td>6025372</td>\n",
       "      <td>A550484-4211884-040715-324_B11</td>\n",
       "      <td>6025372</td>\n",
       "      <td>UKBB</td>\n",
       "      <td>Batch_b004</td>\n",
       "      <td>SMP4_0014395A</td>\n",
       "      <td>B11</td>\n",
       "      <td>99.080</td>\n",
       "      <td>0.98000</td>\n",
       "      <td>28.2300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408415 rows × 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       eid_correct                         Unknown      EID Genotyping Array   \n",
       "0          1000013  A550484-4256924-081516-126_D01  1000013             UKBB  \\\n",
       "1          1000024  A550465-4195810-090314-853_G11  1000024             UKBL   \n",
       "2          1000048  A550484-4256917-081316-053_H04  1000048             UKBB   \n",
       "3          1000055  A550484-4256305-080616-828_F03  1000055             UKBB   \n",
       "4          1000067  A550484-4255254-072116-313_E08  1000067             UKBB   \n",
       "...            ...                             ...      ...              ...   \n",
       "408410     6025313  A550484-4256928-081616-316_A08  6025313             UKBB   \n",
       "408411     6025324  A550484-4248959-050516-528_B08  6025324             UKBB   \n",
       "408412     6025348  A550484-4261892-101716-410_A05  6025348             UKBB   \n",
       "408413     6025355  A550484-4245646-040516-701_G07  6025355             UKBB   \n",
       "408414     6025372  A550484-4211884-040715-324_B11  6025372             UKBB   \n",
       "\n",
       "                 Batch     Plate.Name Well  Cluster.CR      dQC   \n",
       "0           Batch_b085  SMP4_0014675A  D01      99.791  0.98000  \\\n",
       "1       UKBiLEVEAX_b10   SMP4_0008989  G11      99.144  0.98328   \n",
       "2           Batch_b086  SMP4_0015928A  H04      99.800  0.99000   \n",
       "3           Batch_b090  SMP4_0012484A  F03      99.750  0.98000   \n",
       "4           Batch_b084  SMP4_0009406A  E08      99.007  0.96000   \n",
       "...                ...            ...  ...         ...      ...   \n",
       "408410      Batch_b085  SMP4_0015885A  A08      99.730  0.99000   \n",
       "408411      Batch_b073  SMP4_0010000A  B08      99.482  0.98000   \n",
       "408412      Batch_b094  SMP4_0018028A  A05      99.708  0.97000   \n",
       "408413      Batch_b062  SMP4_0012176B  G07      99.792  0.97000   \n",
       "408414      Batch_b004  SMP4_0014395A  B11      99.080  0.98000   \n",
       "\n",
       "        Internal.Pico  ... X21.38740824_A_G_G X21.39972727_C_A_A   \n",
       "0             38.9200  ...                  0                  2  \\\n",
       "1             42.4077  ...                  0                  1   \n",
       "2             33.7400  ...                  1                  0   \n",
       "3             40.3500  ...                  0                  1   \n",
       "4             29.0900  ...                  1                  0   \n",
       "...               ...  ...                ...                ...   \n",
       "408410        32.7300  ...                  0                  1   \n",
       "408411        21.3100  ...                  0                  2   \n",
       "408412        39.1300  ...                  1                  1   \n",
       "408413        20.8300  ...                  0                  0   \n",
       "408414        28.2300  ...                  1                  1   \n",
       "\n",
       "        X21.44357419_T_G_T  X22.22599537_G_A_A X22.29656431_C_T_T   \n",
       "0                        0                   0                  0  \\\n",
       "1                        0                   0                  0   \n",
       "2                        0                   0                  0   \n",
       "3                        2                   0                  0   \n",
       "4                        2                   0                  0   \n",
       "...                    ...                 ...                ...   \n",
       "408410                   1                   0                  0   \n",
       "408411                   2                   0                  0   \n",
       "408412                   0                   0                  0   \n",
       "408413                   2                   0                  0   \n",
       "408414                   0                   0                  0   \n",
       "\n",
       "       X22.39738425_A_C_A  X22.39738501_G_C_G  X22.39743170_G_T_G   \n",
       "0                       0                   0                   0  \\\n",
       "1                       0                   0                   0   \n",
       "2                       0                   0                   0   \n",
       "3                       1                   1                   1   \n",
       "4                       0                   0                   0   \n",
       "...                   ...                 ...                 ...   \n",
       "408410                  1                   1                   1   \n",
       "408411                  0                   0                   0   \n",
       "408412                  1                   1                   1   \n",
       "408413                  0                   0                   0   \n",
       "408414                  0                   0                   0   \n",
       "\n",
       "        X22.39758541_A_G_A  X22.39758881_A_G_A  \n",
       "0                        0                   0  \n",
       "1                        0                   0  \n",
       "2                        0                   0  \n",
       "3                        0                   0  \n",
       "4                        0                   0  \n",
       "...                    ...                 ...  \n",
       "408410                   0                   0  \n",
       "408411                   0                   0  \n",
       "408412                   0                   0  \n",
       "408413                   0                   0  \n",
       "408414                   0                   0  \n",
       "\n",
       "[408415 rows x 708 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_cases = pd.read_csv(\"Data/pdcases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_cases = updated_cases.rename({'eid':'eid_correct'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_cases['eid_correct']=updated_cases.eid_correct.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_cases['Parkinsons']=updated_cases.Parkinsons.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eid_correct']=df.eid_correct.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -12.88610\n",
       "1        -13.96610\n",
       "2        -13.23760\n",
       "3        -13.57610\n",
       "4        -13.36980\n",
       "            ...   \n",
       "408410   -13.49300\n",
       "408411   -13.22600\n",
       "408412   -12.96610\n",
       "408413    -8.94942\n",
       "408414   -11.73810\n",
       "Name: PCA1, Length: 408415, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PCA1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'Parkinsons':'Parkinsons_old'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.merge(updated_cases, on=\"eid_correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1595.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Parkinsons_old.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eid = df[\"eid_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eid.to_csv(\"eid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eid_correct</th>\n",
       "      <td>eid_correct</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EID</th>\n",
       "      <td>EID</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genotyping Array</th>\n",
       "      <td>Genotyping Array</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch</th>\n",
       "      <td>Batch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22.39738501_G_C_G</th>\n",
       "      <td>X22.39738501_G_C_G</td>\n",
       "      <td>0.862559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22.39743170_G_T_G</th>\n",
       "      <td>X22.39743170_G_T_G</td>\n",
       "      <td>1.150078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22.39758541_A_G_A</th>\n",
       "      <td>X22.39758541_A_G_A</td>\n",
       "      <td>3.283699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X22.39758881_A_G_A</th>\n",
       "      <td>X22.39758881_A_G_A</td>\n",
       "      <td>5.175108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parkinsons</th>\n",
       "      <td>Parkinsons</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>709 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           column_name  percent_missing\n",
       "eid_correct                eid_correct         0.000000\n",
       "Unknown                        Unknown         0.000000\n",
       "EID                                EID         0.000000\n",
       "Genotyping Array      Genotyping Array         0.000000\n",
       "Batch                            Batch         0.000000\n",
       "...                                ...              ...\n",
       "X22.39738501_G_C_G  X22.39738501_G_C_G         0.862559\n",
       "X22.39743170_G_T_G  X22.39743170_G_T_G         1.150078\n",
       "X22.39758541_A_G_A  X22.39758541_A_G_A         3.283699\n",
       "X22.39758881_A_G_A  X22.39758881_A_G_A         5.175108\n",
       "Parkinsons                  Parkinsons         0.000000\n",
       "\n",
       "[709 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset Data, Remove high missingness, then mode impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unknown', 'EID', 'Genotyping Array', 'Batch', 'Plate.Name', 'Well',\n",
       "       'Cluster.CR', 'dQC', 'Internal.Pico', 'Submitted_Gender',\n",
       "       'Inferred_Gender', 'X.intensity', 'Y.intensity', 'Submitted Plate Name',\n",
       "       'Submitted.Well', 'Sample.QC.Missing.Rate', 'Heterozygosity',\n",
       "       'Heterozygosity.pc.corrected', 'het.missing.outliers',\n",
       "       'Putative.sex.chromosome.aneuplodiy', 'in.kinship.table',\n",
       "       'excluded.from.kinship.inference', 'excess.relatives',\n",
       "       'in.white.british.ancestry.subset', 'used.in.pca', 'PCA1', 'PCA2',\n",
       "       'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10',\n",
       "       'PCA11', 'PCA12', 'PCA13', 'PCA14', 'PCA15', 'PCA16', 'PCA17', 'PCA18',\n",
       "       'PCA19', 'PCA20', 'PCA21', 'PCA22', 'PCA23', 'PCA24', 'PCA25', 'PCA26',\n",
       "       'PCA27', 'PCA28', 'PCA29', 'PCA30', 'PCA31', 'PCA32', 'PCA33', 'PCA34',\n",
       "       'PCA35', 'PCA36', 'PCA37', 'PCA38', 'PCA39', 'PCA40',\n",
       "       'in.Phasing.Input.chr1_22', 'in.Phasing.Input.chrX',\n",
       "       'in.Phasing.Input.chrXY', 'Ethnicity', 'Birth', 'Parkinsons_old', 'Age',\n",
       "       'X1.8495945_T_C_C', 'X1.20149058_A_G_G', 'X1.20149560_G_A_A',\n",
       "       'X1.20150839_A_G_G', 'X1.20150984_C_G_G', 'X1.20150998_A_G_G',\n",
       "       'X1.20151290_C_A_A', 'X1.20151431_A_G_G', 'X1.20151939_G_C_C',\n",
       "       'X1.20155678_C_T_T', 'X1.20157585_A_T_T', 'X1.20158241_T_C_C',\n",
       "       'X1.20158604_T_G_G', 'X1.20159225_T_A_A', 'X1.20159823_T_G_G',\n",
       "       'X1.22726564_A_G_G', 'X1.22728093_G_A_A', 'X1.75965414_G_C_G',\n",
       "       'X1.90992380_C_T_T', 'X1.92790752_C_T_T', 'X1.93837133_T_C_T',\n",
       "       'X1.108176287_C_T_T', 'X1.151115007_G_A_A', 'X1.154837939_A_G_G',\n",
       "       'X1.155026114_C_T_C', 'X1.155033317_T_C_T', 'X1.155033918_C_T_T'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Parkinsons_old\", \"Batch\", \"Genotyping Array\", \"Unknown\", \"EID\", \"Plate.Name\", \"Well\", \"Cluster.CR\", \"dQC\", \"Internal.Pico\", \"Submitted_Gender\", \"X.intensity\", \"Y.intensity\", 'Submitted Plate Name',\n",
    "       'Submitted.Well', 'Sample.QC.Missing.Rate', 'Heterozygosity',\n",
    "       'Heterozygosity.pc.corrected', 'het.missing.outliers',\n",
    "       'Putative.sex.chromosome.aneuplodiy', 'in.kinship.table',\n",
    "       'excluded.from.kinship.inference', 'excess.relatives',\n",
    "       'in.white.british.ancestry.subset', 'used.in.pca', 'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8','PCA9', 'PCA10', \"PCA11\", \"PCA12\", 'PCA13', 'PCA14', 'PCA15', 'PCA16', 'PCA17', 'PCA18',\n",
    "       'PCA19', 'PCA20', 'PCA21', 'PCA22', 'PCA23', 'PCA24', 'PCA25', 'PCA26',\n",
    "       'PCA27', 'PCA28', 'PCA29', 'PCA30', 'PCA31', 'PCA32', 'PCA33', 'PCA34',\n",
    "       'PCA35', 'PCA36', 'PCA37', 'PCA38', 'PCA39', 'PCA40', 'in.Phasing.Input.chr1_22',\n",
    "        'in.Phasing.Input.chrX',\n",
    "       'in.Phasing.Input.chrXY', 'Ethnicity'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "limitPer = len(df) * .15\n",
    "df = df.dropna(thresh=limitPer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid_correct</th>\n",
       "      <th>Inferred_Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>X1.8495945_T_C_C</th>\n",
       "      <th>X1.20149058_A_G_G</th>\n",
       "      <th>X1.20149560_G_A_A</th>\n",
       "      <th>X1.20150839_A_G_G</th>\n",
       "      <th>X1.20150984_C_G_G</th>\n",
       "      <th>X1.20150998_A_G_G</th>\n",
       "      <th>X1.20151290_C_A_A</th>\n",
       "      <th>...</th>\n",
       "      <th>X21.39972727_C_A_A</th>\n",
       "      <th>X21.44357419_T_G_T</th>\n",
       "      <th>X22.22599537_G_A_A</th>\n",
       "      <th>X22.29656431_C_T_T</th>\n",
       "      <th>X22.39738425_A_C_A</th>\n",
       "      <th>X22.39738501_G_C_G</th>\n",
       "      <th>X22.39743170_G_T_G</th>\n",
       "      <th>X22.39758541_A_G_A</th>\n",
       "      <th>X22.39758881_A_G_A</th>\n",
       "      <th>Parkinsons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000013.0</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000024.0</td>\n",
       "      <td>F</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000048.0</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000055.0</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000067.0</td>\n",
       "      <td>M</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408315</th>\n",
       "      <td>6025313.0</td>\n",
       "      <td>F</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408316</th>\n",
       "      <td>6025324.0</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408317</th>\n",
       "      <td>6025348.0</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408318</th>\n",
       "      <td>6025355.0</td>\n",
       "      <td>F</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408319</th>\n",
       "      <td>6025372.0</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408320 rows × 639 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        eid_correct Inferred_Gender  Age X1.8495945_T_C_C X1.20149058_A_G_G   \n",
       "0         1000013.0               F   46                0                 0  \\\n",
       "1         1000024.0               F   66                0                 2   \n",
       "2         1000048.0               M   63                1                 1   \n",
       "3         1000055.0               F   52                2                 1   \n",
       "4         1000067.0               M   46                1                 0   \n",
       "...             ...             ...  ...              ...               ...   \n",
       "408315    6025313.0               F   64                1                 0   \n",
       "408316    6025324.0               M   50                1                 0   \n",
       "408317    6025348.0               M   60                0                 0   \n",
       "408318    6025355.0               F   43                1                 0   \n",
       "408319    6025372.0               M   59                0                 2   \n",
       "\n",
       "       X1.20149560_G_A_A X1.20150839_A_G_G X1.20150984_C_G_G   \n",
       "0                      0                 0                 0  \\\n",
       "1                      2                 2                 2   \n",
       "2                      1                 1                 1   \n",
       "3                      1                 1                 1   \n",
       "4                      0                 0                 0   \n",
       "...                  ...               ...               ...   \n",
       "408315                 0                 0                 0   \n",
       "408316               NaN               NaN               NaN   \n",
       "408317                 0                 0                 0   \n",
       "408318                 0                 0                 0   \n",
       "408319                 2                 2                 2   \n",
       "\n",
       "       X1.20150998_A_G_G X1.20151290_C_A_A  ... X21.39972727_C_A_A   \n",
       "0                      0                 0  ...                  2  \\\n",
       "1                      2                 2  ...                  1   \n",
       "2                      1                 1  ...                  0   \n",
       "3                      1                 1  ...                  1   \n",
       "4                      0                 0  ...                  0   \n",
       "...                  ...               ...  ...                ...   \n",
       "408315                 0                 0  ...                  1   \n",
       "408316               NaN                 0  ...                  2   \n",
       "408317                 0                 0  ...                  1   \n",
       "408318                 0                 0  ...                  0   \n",
       "408319                 2                 2  ...                  1   \n",
       "\n",
       "       X21.44357419_T_G_T  X22.22599537_G_A_A X22.29656431_C_T_T   \n",
       "0                       0                   0                  0  \\\n",
       "1                       0                   0                  0   \n",
       "2                       0                   0                  0   \n",
       "3                       2                   0                  0   \n",
       "4                       2                   0                  0   \n",
       "...                   ...                 ...                ...   \n",
       "408315                  1                   0                  0   \n",
       "408316                  2                   0                  0   \n",
       "408317                  0                   0                  0   \n",
       "408318                  2                   0                  0   \n",
       "408319                  0                   0                  0   \n",
       "\n",
       "        X22.39738425_A_C_A X22.39738501_G_C_G X22.39743170_G_T_G   \n",
       "0                        0                  0                  0  \\\n",
       "1                        0                  0                  0   \n",
       "2                        0                  0                  0   \n",
       "3                        1                  1                  1   \n",
       "4                        0                  0                  0   \n",
       "...                    ...                ...                ...   \n",
       "408315                   1                  1                  1   \n",
       "408316                   0                  0                  0   \n",
       "408317                   1                  1                  1   \n",
       "408318                   0                  0                  0   \n",
       "408319                   0                  0                  0   \n",
       "\n",
       "       X22.39758541_A_G_A X22.39758881_A_G_A  Parkinsons  \n",
       "0                       0                  0         0.0  \n",
       "1                       0                  0         0.0  \n",
       "2                       0                  0         0.0  \n",
       "3                       0                  0         0.0  \n",
       "4                       0                  0         0.0  \n",
       "...                   ...                ...         ...  \n",
       "408315                  0                  0         0.0  \n",
       "408316                  0                  0         0.0  \n",
       "408317                  0                  0         0.0  \n",
       "408318                  0                  0         0.0  \n",
       "408319                  0                  0         0.0  \n",
       "\n",
       "[408320 rows x 639 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(df.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = np.asarray(df.Parkinsons)\n",
    "df['Y'] = pd.Series(df_target)\n",
    "\n",
    "# input\n",
    "#X = df.iloc[:, :-1]\n",
    "\n",
    "#output\n",
    "#Y = df.iloc[:, -1]\n",
    "\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop([\"Batch\"], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Parkinsons\"], axis=1, inplace=True)\n",
    "df['Inferred_Gender'].replace(['F','M'],[0,1],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eid_correct               0\n",
       "Inferred_Gender           0\n",
       "Age                       0\n",
       "X1.8495945_T_C_C       4795\n",
       "X1.20149058_A_G_G      3746\n",
       "                      ...  \n",
       "X22.39738501_G_C_G     3522\n",
       "X22.39743170_G_T_G     4696\n",
       "X22.39758541_A_G_A    13408\n",
       "X22.39758881_A_G_A    21131\n",
       "Y                         0\n",
       "Length: 639, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"ukbiobank_variantsonly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Genotyping Array'].replace(['UKBB','UKBL'],[0,1],inplace=True)\n",
    "#df[\"Batch\"] = pd.factorize(df.Batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape of X = (244992, 638) and Y = (244992,) : \n",
      "Test data shape of X = (163328, 638) and Y = (163328,) : \n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:, :-1], df.iloc[:, -1],\n",
    "    test_size = 0.40, random_state=1)\n",
    "\n",
    "print(\"Train data shape of X = % s and Y = % s : \"%(\n",
    "    x_train.shape, y_train.shape))\n",
    "\n",
    "print(\"Test data shape of X = % s and Y = % s : \"%(\n",
    "    x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y\n",
       "0.0    161909\n",
       "1.0      1419\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Age', 'Inferred_Gender', 'X1.108176287_C_T_T',\n",
       "       'X1.151115007_G_A_A', 'X1.154837939_A_G_G', 'X1.155026114_C_T_C',\n",
       "       'X1.155033317_T_C_T', 'X1.155033918_C_T_T', 'X1.155034632_C_G_G',\n",
       "       'X1.155044197_T_G_G', 'X1.155074903_G_T_G', 'X1.155076043_C_T_C',\n",
       "       'X1.155076505_A_G_A', 'X1.155076734_C_T_C', 'X1.155080090_A_G_A',\n",
       "       'X1.155081940_T_C_T', 'X1.155082298_T_C_T', 'X1.155083942_T_C_T',\n",
       "       'X1.155097562_C_G_G', 'X1.155198771_A_G_G', 'X1.160742649_C_T_C',\n",
       "       'X1.160742850_A_G_A', 'X1.160970089_C_T_T', 'X1.161389646_G_A_A',\n",
       "       'X1.161452866_G_T_T', 'X1.161468430_C_T_T', 'X1.171719769_C_T_T',\n",
       "       'X1.171863472_T_G_G', 'X1.183517524_T_C_C', 'X1.20149058_A_G_G',\n",
       "       'X1.20149560_G_A_A', 'X1.20150839_A_G_G', 'X1.20150984_C_G_G',\n",
       "       'X1.20150998_A_G_G', 'X1.20151290_C_A_A', 'X1.20151431_A_G_G',\n",
       "       'X1.20151939_G_C_C', 'X1.20155678_C_T_T', 'X1.20157585_A_T_T',\n",
       "       'X1.20158241_T_C_C', 'X1.20158604_T_G_G', 'X1.20159225_T_A_A',\n",
       "       'X1.205723572_C_T_C', 'X1.226797733_G_A_A', 'X1.226916078_T_C_C',\n",
       "       'X1.22726564_A_G_G', 'X1.22728093_G_A_A', 'X1.232664611_C_T_T',\n",
       "       'X1.75965414_G_C_G', 'X1.8495945_T_C_C', 'X1.90992380_C_T_T',\n",
       "       'X1.92790752_C_T_T', 'X1.93837133_T_C_T', 'X10.103550281_G_T_T',\n",
       "       'X10.103940629_G_A_A', 'X10.104015279_A_G_G',\n",
       "       'X10.104606615_T_C_C', 'X10.121361986_C_T_T',\n",
       "       'X10.121536327_G_A_A', 'X10.121679013_A_G_A',\n",
       "       'X10.121842595_G_A_A', 'X10.123842523_G_A_A',\n",
       "       'X10.123846288_G_A_A', 'X10.126502854_C_T_T',\n",
       "       'X10.132926408_G_A_A', 'X10.15563450_C_T_C', 'X10.2766921_G_A_G',\n",
       "       'X10.35533707_G_A_A', 'X10.35557933_C_T_T', 'X10.35559567_T_C_C',\n",
       "       'X10.35563776_T_G_G', 'X10.35565071_C_T_T', 'X10.35612545_G_A_A',\n",
       "       'X10.35662791_C_T_T', 'X10.35668587_T_A_A', 'X10.35668965_C_T_T',\n",
       "       'X10.35678983_C_T_T', 'X10.35704802_G_A_A', 'X10.35709240_G_A_A',\n",
       "       'X10.35715413_T_A_A', 'X10.35733661_A_T_T', 'X10.35747724_C_A_A',\n",
       "       'X10.35750374_A_C_C', 'X10.35761414_T_C_C', 'X10.35779999_G_A_A',\n",
       "       'X10.35785779_C_T_T', 'X10.35789417_G_A_A', 'X10.35792410_C_G_G',\n",
       "       'X10.35840750_A_T_T', 'X10.35853425_A_G_G', 'X10.35873777_A_G_G',\n",
       "       'X10.46121886_C_T_T', 'X10.50821191_G_T_G', 'X10.54879218_A_G_G',\n",
       "       'X10.54880387_A_C_C', 'X10.56689984_G_T_T', 'X10.6081462_A_G_G',\n",
       "       'X10.6092989_C_T_T', 'X10.6094679_G_A_A', 'X10.6101524_G_A_A',\n",
       "       'X10.6183814_G_A_A', 'X10.6632290_G_A_A', 'X10.71062880_A_C_A',\n",
       "       'X10.78157572_T_C_C', 'X10.8011423_A_C_C', 'X10.90027875_G_A_A',\n",
       "       'X11.108138003_T_C_C', 'X11.10820384_A_C_A', 'X11.118620697_T_C_C',\n",
       "       'X11.124180643_G_T_T', 'X11.2200949_A_G_A', 'X11.3700876_C_T_T',\n",
       "       'X11.549119_T_G_T', 'X11.5895414_T_C_C', 'X11.60835596_C_T_C',\n",
       "       'X11.6341684_C_G_C', 'X11.63806993_C_T_T', 'X11.71807767_A_C_C',\n",
       "       'X11.93561149_G_A_A', 'X12.116457090_C_T_T', 'X12.117175608_C_T_T',\n",
       "       'X12.123326598_G_T_T', 'X12.123345509_G_T_T',\n",
       "       'X12.123585705_C_T_T', 'X12.124134802_C_T_T',\n",
       "       'X12.130992170_A_G_G', 'X12.133063768_G_A_A',\n",
       "       'X12.133257837_C_A_A', 'X12.21418143_C_T_T', 'X12.40380035_G_A_A',\n",
       "       'X12.40388109_C_T_T', 'X12.40575173_C_T_T', 'X12.40614434_C_T_T',\n",
       "       'X12.40614656_A_G_A', 'X12.40698422_C_T_T', 'X12.40707861_C_T_T',\n",
       "       'X12.40713899_T_C_C', 'X12.40753796_T_C_C', 'X12.40829565_G_A_A',\n",
       "       'X12.41006567_T_C_C', 'X12.41251554_A_G_G', 'X12.49472965_G_A_A',\n",
       "       'X12.54023491_G_A_A', 'X12.57848639_G_A_G', 'X12.6423900_A_G_G',\n",
       "       'X12.72179446_C_T_T', 'X12.78636050_T_C_T', 'X13.103345465_T_C_C',\n",
       "       'X13.113530199_G_A_A', 'X13.20767957_G_T_G', 'X13.46594619_T_C_C',\n",
       "       'X13.49927732_T_C_C', 'X13.60545105_G_T_T', 'X13.86229641_T_C_T',\n",
       "       'X13.97865021_T_C_T', 'X13.98139677_T_C_T', 'X14.101979288_G_A_A',\n",
       "       'X14.104399640_G_A_A', 'X14.105623612_T_C_T', 'X14.25880510_A_C_A',\n",
       "       'X14.25887879_G_A_A', 'X14.47246378_C_T_C', 'X14.55348869_C_T_T',\n",
       "       'X14.56191413_C_T_T', 'X14.63098431_A_G_A', 'X14.74976452_C_T_T',\n",
       "       'X14.88472612_C_T_T', 'X14.88620757_G_A_A', 'X15.41798614_T_C_C',\n",
       "       'X15.63348087_A_G_A', 'X15.72189952_T_A_A', 'X15.76017452_C_T_T',\n",
       "       'X15.98512431_C_T_T', 'X15.98876029_G_C_C', 'X16.11002927_A_G_A',\n",
       "       'X16.11151228_C_T_T', 'X16.11174365_G_A_A', 'X16.11231857_G_A_A',\n",
       "       'X16.12060163_A_G_A', 'X16.19279380_T_C_T', 'X16.28513827_A_G_G',\n",
       "       'X16.28515228_A_C_C', 'X16.28519693_G_A_A', 'X16.28523248_G_A_A',\n",
       "       'X16.28566158_G_T_T', 'X16.28622480_T_C_C', 'X16.28838018_T_C_C',\n",
       "       'X16.28843327_C_G_G', 'X16.28861624_G_C_C', 'X16.28985450_C_T_T',\n",
       "       'X16.30471109_T_C_T', 'X16.30482494_T_C_T', 'X16.30485393_G_C_G',\n",
       "       'X16.30493881_T_C_T', 'X16.30495412_T_C_T', 'X16.30495496_C_T_T',\n",
       "       'X16.30500985_A_G_A', 'X16.30510571_C_T_T', 'X16.30520856_C_T_T',\n",
       "       'X16.30553899_A_G_G', 'X16.31004169_T_C_C', 'X16.31370452_C_T_C',\n",
       "       'X16.50736656_A_G_G', 'X16.52636242_C_A_A', 'X16.68600595_A_G_G',\n",
       "       'X16.68628543_A_C_C', 'X16.68638730_G_A_A', 'X16.82455819_T_C_C',\n",
       "       'X16.82637134_A_G_G', 'X16.88909159_G_T_T', 'X16.89986117_C_T_T',\n",
       "       'X17.16203290_C_A_A', 'X17.18003845_C_T_C', 'X17.18063441_T_C_T',\n",
       "       'X17.40741013_T_C_C', 'X17.42786711_G_A_A', 'X17.42929985_G_T_T',\n",
       "       'X17.43060768_T_G_G', 'X17.43417273_G_T_T', 'X17.43472507_A_G_G',\n",
       "       'X17.43744203_C_T_T', 'X17.43784228_T_C_T', 'X17.43935838_T_C_T',\n",
       "       'X17.43993376_T_G_G', 'X17.44019712_G_A_A', 'X17.44071851_G_A_A',\n",
       "       'X17.44189067_A_G_G', 'X17.44981466_T_C_C', 'X17.60188441_G_A_A',\n",
       "       'X17.61666687_C_T_T', 'X17.64141919_T_A_A', 'X17.72725478_C_G_G',\n",
       "       'X18.33102339_T_C_C', 'X18.40628467_T_C_T', 'X18.40673380_A_G_G',\n",
       "       'X18.60985879_T_C_C', 'X18.67950442_T_G_G', 'X19.2322165_G_A_A',\n",
       "       'X19.46304585_G_T_T', 'X19.47615835_C_T_T', 'X19.54753126_G_C_C',\n",
       "       'X2.102570469_G_A_A', 'X2.102576880_G_C_C', 'X2.102638615_C_T_T',\n",
       "       'X2.111854524_C_T_T', 'X2.135443940_A_G_G', 'X2.135803425_G_T_G',\n",
       "       'X2.135925002_T_G_G', 'X2.164451154_C_T_T', 'X2.169161223_C_T_C',\n",
       "       'X2.170964822_T_G_G', 'X2.170965121_G_A_A', 'X2.170966684_G_A_G',\n",
       "       'X2.181890819_C_T_T', 'X2.183616913_A_C_C', 'X2.191364828_C_T_T',\n",
       "       'X2.201253956_A_G_G', 'X2.218816702_C_T_T', 'X2.227853157_G_A_A',\n",
       "       'X2.234143062_C_T_T', 'X2.236943672_C_T_C', 'X2.239323169_A_G_A',\n",
       "       'X2.241652703_T_C_C', 'X2.241653287_A_G_G', 'X2.26191490_G_A_A',\n",
       "       'X2.31832807_T_C_T', 'X2.32503526_T_C_T', 'X2.32811909_A_G_A',\n",
       "       'X2.33246146_G_A_A', 'X2.38537579_T_C_C', 'X2.61763207_T_C_T',\n",
       "       'X20.25275266_T_C_C', 'X20.25539937_C_T_T', 'X20.25672987_G_A_A',\n",
       "       'X20.26182690_A_G_G', 'X20.2828596_A_G_G', 'X20.3164686_T_C_C',\n",
       "       'X20.31877713_A_T_T', 'X20.40904924_C_T_T', 'X20.43207483_A_T_T',\n",
       "       'X20.48618781_C_T_T', 'X20.62294447_G_A_A', 'X21.16812882_C_T_T',\n",
       "       'X21.38740824_A_G_G', 'X21.39972727_C_A_A', 'X22.29656431_C_T_T',\n",
       "       'X22.39738425_A_C_A', 'X22.39738501_G_C_G', 'X22.39743170_G_T_G',\n",
       "       'X22.39758541_A_G_A', 'X22.39758881_A_G_A', 'X3.160812752_C_T_T',\n",
       "       'X3.163861651_A_G_A', 'X3.163915341_A_G_A', 'X3.176417139_G_A_A',\n",
       "       'X3.176423123_A_G_G', 'X3.182760073_T_G_G', 'X3.18361759_A_C_C',\n",
       "       'X3.185834290_T_C_T', 'X3.18674261_C_T_T', 'X3.197701913_G_T_T',\n",
       "       'X3.28700178_A_G_A', 'X3.29629760_C_T_T', 'X3.39307162_G_A_A',\n",
       "       'X3.46141902_T_C_T', 'X3.48748989_G_T_G', 'X3.49162583_C_T_T',\n",
       "       'X3.49450137_C_A_A', 'X3.49463700_C_T_T', 'X3.49568181_G_A_A',\n",
       "       'X3.49740895_A_G_G', 'X3.50154223_T_C_C', 'X3.51929183_C_T_T',\n",
       "       'X3.52261031_A_G_G', 'X3.58292485_G_A_A', 'X3.64634411_T_C_C',\n",
       "       'X3.64636128_G_A_A', 'X4.1008212_C_T_T', 'X4.1024287_T_C_C',\n",
       "       'X4.102753817_G_A_A', 'X4.102920373_T_C_C', 'X4.102926923_G_A_A',\n",
       "       'X4.103188709_C_T_T', 'X4.114369065_C_T_T', 'X4.114447191_G_A_G',\n",
       "       'X4.122979432_C_T_T', 'X4.124770865_A_G_G', 'X4.1312394_C_T_T',\n",
       "       'X4.14167196_A_G_G', 'X4.15737348_G_A_G', 'X4.15751051_G_A_A',\n",
       "       'X4.15753687_A_G_G', 'X4.15777881_C_T_C', 'X4.15794069_G_A_G',\n",
       "       'X4.15796333_A_G_A', 'X4.15829612_A_G_A', 'X4.15833532_A_G_A',\n",
       "       'X4.15840839_A_G_A', 'X4.17953590_A_G_G', 'X4.2451467_G_A_A',\n",
       "       'X4.47221089_T_G_G', 'X4.56820412_G_A_A', 'X4.749620_T_G_G',\n",
       "       'X4.77076710_G_A_A', 'X4.77100807_T_C_C', 'X4.77147969_A_G_G',\n",
       "       'X4.77198054_C_T_T', 'X4.77222933_A_C_A', 'X4.831852_A_C_C',\n",
       "       'X4.88533540_A_T_T', 'X4.88732874_A_G_G', 'X4.90205253_C_A_C',\n",
       "       'X4.90368545_G_A_A', 'X4.90412435_A_G_G', 'X4.90441114_T_C_C',\n",
       "       'X4.90513701_G_A_A', 'X4.90579508_G_A_A', 'X4.90594987_G_A_A',\n",
       "       'X4.90619032_C_T_T', 'X4.90624593_T_C_C', 'X4.90700329_T_C_C',\n",
       "       'X4.90757294_A_C_A', 'X4.90788943_G_A_A', 'X4.90882543_C_T_T',\n",
       "       'X4.90982912_A_G_G', 'X4.91057794_A_G_G', 'X4.91164040_C_T_T',\n",
       "       'X4.94159851_G_T_T', 'X4.951947_T_C_C', 'X4.96372611_C_T_T',\n",
       "       'X5.102363402_C_T_C', 'X5.102660400_T_C_C', 'X5.131680264_G_A_A',\n",
       "       'X5.132754003_A_G_A', 'X5.133924478_T_C_C', 'X5.134199105_C_A_A',\n",
       "       'X5.141605252_T_C_C', 'X5.141605948_T_C_C', 'X5.149784414_C_T_T',\n",
       "       'X5.36000291_C_T_T', 'X5.55250727_A_G_G', 'X5.55436316_T_C_C',\n",
       "       'X5.60297500_A_G_A', 'X5.79846926_T_C_C', 'X5.87513775_C_T_C',\n",
       "       'X5.96223552_G_A_A', 'X6.111829239_A_G_A', 'X6.112138882_G_A_A',\n",
       "       'X6.112150430_A_G_G', 'X6.112164313_G_A_A', 'X6.119396266_T_C_C',\n",
       "       'X6.126249914_T_G_G', 'X6.159340625_G_T_T', 'X6.16007218_C_A_A',\n",
       "       'X6.167355916_A_G_G', 'X6.168625719_G_A_A', 'X6.170143300_A_G_G',\n",
       "       'X6.18130918_T_C_C', 'X6.18139228_C_T_T', 'X6.24399181_A_C_C',\n",
       "       'X6.27299567_T_C_C', 'X6.27681215_G_A_A', 'X6.28037020_G_T_T',\n",
       "       'X6.28054198_A_G_G', 'X6.29723674_T_C_C', 'X6.30109861_A_C_C',\n",
       "       'X6.30241114_A_G_G', 'X6.30280125_A_C_C', 'X6.30281402_G_C_C',\n",
       "       'X6.30286729_C_T_T', 'X6.30292083_T_C_C', 'X6.30309105_G_A_A',\n",
       "       'X6.30376864_A_G_G', 'X6.30383768_A_G_G', 'X6.30632655_T_C_C',\n",
       "       'X6.30739904_G_A_A', 'X6.31063413_T_C_T', 'X6.31173433_G_A_A',\n",
       "       'X6.31184949_G_A_A', 'X6.31352631_A_G_G', 'X6.31378510_G_A_A',\n",
       "       'X6.31378714_A_T_T', 'X6.31379109_G_A_A', 'X6.31382147_G_C_C',\n",
       "       'X6.31382882_C_A_A', 'X6.31383108_T_C_C', 'X6.31384792_T_C_C',\n",
       "       'X6.31388277_C_T_T', 'X6.31390055_G_T_T', 'X6.31407643_T_C_C',\n",
       "       'X6.31407821_A_T_T', 'X6.31412513_G_C_C', 'X6.31431820_C_T_T',\n",
       "       'X6.31590354_G_A_G', 'X6.31846234_A_G_A', 'X6.31915614_G_A_A',\n",
       "       'X6.31920873_C_T_T', 'X6.32109938_G_T_T', 'X6.32213052_A_T_T',\n",
       "       'X6.32219320_G_T_T', 'X6.32221552_G_A_G', 'X6.32230354_A_G_A',\n",
       "       'X6.32257284_T_G_G', 'X6.32282854_A_G_G', 'X6.32303848_G_A_A',\n",
       "       'X6.32333341_A_G_G', 'X6.32341318_A_G_G', 'X6.32341473_T_C_C',\n",
       "       'X6.32341719_C_T_T', 'X6.32342087_C_T_T', 'X6.32342129_C_T_T',\n",
       "       'X6.32343095_T_C_C', 'X6.32343096_G_A_A', 'X6.32343882_C_T_T',\n",
       "       'X6.32344973_G_T_T', 'X6.32345052_A_G_G', 'X6.32347490_C_T_T',\n",
       "       'X6.32347532_C_T_T', 'X6.32349946_C_A_A', 'X6.32350036_A_G_G',\n",
       "       'X6.32350384_C_A_A', 'X6.32350776_G_A_A', 'X6.32350868_A_C_C',\n",
       "       'X6.32351283_T_C_C', 'X6.32354428_A_G_G', 'X6.32355605_G_A_A',\n",
       "       'X6.32355683_A_G_G', 'X6.32357165_T_C_C', 'X6.32358231_C_T_T',\n",
       "       'X6.32358942_T_A_A', 'X6.32359121_G_A_A', 'X6.32363844_C_T_T',\n",
       "       'X6.32364356_A_G_G', 'X6.32367777_A_T_T', 'X6.32367847_T_C_C',\n",
       "       'X6.32371179_G_C_C', 'X6.32371619_A_G_G', 'X6.32374622_A_T_T',\n",
       "       'X6.32375352_A_C_C', 'X6.32375424_G_A_A', 'X6.32375695_G_A_A',\n",
       "       'X6.32376176_C_T_T', 'X6.32376746_C_T_T', 'X6.32378945_T_A_A',\n",
       "       'X6.32379489_C_T_T', 'X6.32409530_G_A_G', 'X6.32410576_T_C_T',\n",
       "       'X6.32411035_A_C_A', 'X6.32428115_G_A_A', 'X6.32428715_G_A_A',\n",
       "       'X6.32669817_T_C_C', 'X6.32682862_C_T_T', 'X6.32733823_C_T_T',\n",
       "       'X6.32804798_G_A_A', 'X6.32861920_A_G_G', 'X6.32950382_T_C_C',\n",
       "       'X6.412802_G_A_G', 'X6.46184459_A_G_G', 'X6.51159995_G_A_A',\n",
       "       'X6.54254589_A_C_C', 'X6.6736557_C_T_T', 'X6.72487762_C_T_T',\n",
       "       'X6.79745107_C_T_C', 'X7.102743893_C_T_C', 'X7.129663496_C_T_T',\n",
       "       'X7.157932055_C_T_T', 'X7.23430418_C_T_T', 'X7.28128002_T_C_C',\n",
       "       'X7.30606700_C_T_T', 'X7.50430493_T_A_A', 'X7.50430769_G_C_C',\n",
       "       'X7.50439198_G_A_A', 'X7.51123343_T_C_T', 'X8.10999583_C_T_T',\n",
       "       'X8.110371435_A_G_G', 'X8.121298156_G_C_C', 'X8.126526686_T_C_C',\n",
       "       'X8.138905296_A_G_A', 'X8.17510766_C_G_G', 'X8.17541943_T_G_G',\n",
       "       'X8.27466315_T_C_T', 'X8.56824771_C_G_C', 'X8.6783479_C_T_T',\n",
       "       'X8.68561738_T_A_A', 'X8.94792887_G_A_A', 'X9.138642022_G_A_A',\n",
       "       'X9.139150738_G_A_A', 'X9.139151148_G_T_T', 'X9.139153375_G_A_A',\n",
       "       'X9.139153592_C_T_T', 'X9.139219709_G_T_T', 'X9.139336813_T_G_G',\n",
       "       'X9.17579690_T_G_T', 'X9.17726888_C_T_T', 'X9.33778399_G_A_G',\n",
       "       'X9.34046391_C_T_C', 'X9.5023192_A_G_G', 'X9.5065003_C_G_G',\n",
       "       'X9.86258685_A_C_C', 'X9.86945961_A_C_C', 'X9.89056018_A_G_G',\n",
       "       'X9.89059858_G_A_A', 'X9.93256092_T_C_T'], dtype='<U19')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.load('columns.csv.npy')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train[b]\n",
    "x_test = x_test[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to match case and control and try random forest. Also imputation and prccice. And add age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.fillna(x_train.mode().iloc[0], inplace=True)\n",
    "x_test.fillna(x_test.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "#pipe.fit(x_train, y_train)  # apply scaling on training data\n",
    "#pipe.score(x_test, y_test)  # apply scaling on testing data, without leaking training data.\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(x_train)\n",
    "#X_test = sc.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.drop([\"Batch\"], axis =1, inplace=True)\n",
    "#x_train.drop([\"Genotyping Array\"], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Inferred_Gender</th>\n",
       "      <th>X1.108176287_C_T_T</th>\n",
       "      <th>X1.151115007_G_A_A</th>\n",
       "      <th>X1.154837939_A_G_G</th>\n",
       "      <th>X1.155026114_C_T_C</th>\n",
       "      <th>X1.155033317_T_C_T</th>\n",
       "      <th>X1.155033918_C_T_T</th>\n",
       "      <th>X1.155034632_C_G_G</th>\n",
       "      <th>X1.155044197_T_G_G</th>\n",
       "      <th>...</th>\n",
       "      <th>X9.17726888_C_T_T</th>\n",
       "      <th>X9.33778399_G_A_G</th>\n",
       "      <th>X9.34046391_C_T_C</th>\n",
       "      <th>X9.5023192_A_G_G</th>\n",
       "      <th>X9.5065003_C_G_G</th>\n",
       "      <th>X9.86258685_A_C_C</th>\n",
       "      <th>X9.86945961_A_C_C</th>\n",
       "      <th>X9.89056018_A_G_G</th>\n",
       "      <th>X9.89059858_G_A_A</th>\n",
       "      <th>X9.93256092_T_C_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282666</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347238</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157205</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39564</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306310</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371403</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312201</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267336</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244992 rows × 543 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Inferred_Gender  X1.108176287_C_T_T  X1.151115007_G_A_A   \n",
       "282666   66                1                   2                   0  \\\n",
       "347238   64                0                   0                   0   \n",
       "157205   44                1                   2                   0   \n",
       "39564    56                0                   0                   0   \n",
       "306310   51                1                   2                   0   \n",
       "...     ...              ...                 ...                 ...   \n",
       "73349    52                1                   1                   0   \n",
       "371403   61                1                   1                   0   \n",
       "312201   62                1                   1                   0   \n",
       "267336   63                1                   0                   0   \n",
       "128037   45                0                   0                   0   \n",
       "\n",
       "        X1.154837939_A_G_G  X1.155026114_C_T_C  X1.155033317_T_C_T   \n",
       "282666                   0                   1                   1  \\\n",
       "347238                   0                   1                   0   \n",
       "157205                   0                   2                   0   \n",
       "39564                    0                   0                   0   \n",
       "306310                   0                   0                   0   \n",
       "...                    ...                 ...                 ...   \n",
       "73349                    0                   0                   0   \n",
       "371403                   0                   0                   0   \n",
       "312201                   0                   2                   1   \n",
       "267336                   0                   1                   1   \n",
       "128037                   0                   0                   1   \n",
       "\n",
       "        X1.155033918_C_T_T  X1.155034632_C_G_G  X1.155044197_T_G_G  ...   \n",
       "282666                   0                   0                   0  ...  \\\n",
       "347238                   1                   1                   0  ...   \n",
       "157205                   0                   0                   0  ...   \n",
       "39564                    1                   1                   0  ...   \n",
       "306310                   0                   0                   0  ...   \n",
       "...                    ...                 ...                 ...  ...   \n",
       "73349                    0                   0                   0  ...   \n",
       "371403                   1                   1                   0  ...   \n",
       "312201                   0                   0                   0  ...   \n",
       "267336                   0                   0                   0  ...   \n",
       "128037                   0                   0                   0  ...   \n",
       "\n",
       "        X9.17726888_C_T_T  X9.33778399_G_A_G  X9.34046391_C_T_C   \n",
       "282666                  0                  0                  0  \\\n",
       "347238                  0                  1                  1   \n",
       "157205                  1                  0                  0   \n",
       "39564                   0                  1                  1   \n",
       "306310                  0                  1                  1   \n",
       "...                   ...                ...                ...   \n",
       "73349                   0                  1                  1   \n",
       "371403                  0                  0                  0   \n",
       "312201                  1                  0                  0   \n",
       "267336                  0                  1                  1   \n",
       "128037                  1                  0                  0   \n",
       "\n",
       "        X9.5023192_A_G_G  X9.5065003_C_G_G  X9.86258685_A_C_C   \n",
       "282666                 0                 0                  1  \\\n",
       "347238                 0                 0                  0   \n",
       "157205                 0                 0                  1   \n",
       "39564                  0                 0                  0   \n",
       "306310                 0                 0                  1   \n",
       "...                  ...               ...                ...   \n",
       "73349                  0                 0                  2   \n",
       "371403                 0                 0                  0   \n",
       "312201                 0                 0                  1   \n",
       "267336                 0                 0                  1   \n",
       "128037                 0                 0                  0   \n",
       "\n",
       "        X9.86945961_A_C_C  X9.89056018_A_G_G  X9.89059858_G_A_A   \n",
       "282666                  0                  2                  2  \\\n",
       "347238                  0                  1                  1   \n",
       "157205                  0                  1                  1   \n",
       "39564                   0                  1                  1   \n",
       "306310                  0                  1                  1   \n",
       "...                   ...                ...                ...   \n",
       "73349                   0                  0                  0   \n",
       "371403                  0                  1                  1   \n",
       "312201                  0                  0                  0   \n",
       "267336                  0                  1                  1   \n",
       "128037                  0                  0                  0   \n",
       "\n",
       "        X9.93256092_T_C_T  \n",
       "282666                  0  \n",
       "347238                  0  \n",
       "157205                  1  \n",
       "39564                   0  \n",
       "306310                  1  \n",
       "...                   ...  \n",
       "73349                   1  \n",
       "371403                  2  \n",
       "312201                  0  \n",
       "267336                  1  \n",
       "128037                  1  \n",
       "\n",
       "[244992 rows x 543 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test.drop([\"Batch\"], axis =1, inplace=True)\n",
    "#x_test.drop([\"Genotyping Array\"], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.append(b, \"eid_correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid_correct</th>\n",
       "      <th>Inferred_Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>X1.8495945_T_C_C</th>\n",
       "      <th>X1.20149058_A_G_G</th>\n",
       "      <th>X1.20149560_G_A_A</th>\n",
       "      <th>X1.20150839_A_G_G</th>\n",
       "      <th>X1.20150984_C_G_G</th>\n",
       "      <th>X1.20150998_A_G_G</th>\n",
       "      <th>X1.20151290_C_A_A</th>\n",
       "      <th>...</th>\n",
       "      <th>X21.38740824_A_G_G</th>\n",
       "      <th>X21.39972727_C_A_A</th>\n",
       "      <th>X21.44357419_T_G_T</th>\n",
       "      <th>X22.22599537_G_A_A</th>\n",
       "      <th>X22.29656431_C_T_T</th>\n",
       "      <th>X22.39738425_A_C_A</th>\n",
       "      <th>X22.39738501_G_C_G</th>\n",
       "      <th>X22.39743170_G_T_G</th>\n",
       "      <th>X22.39758541_A_G_A</th>\n",
       "      <th>X22.39758881_A_G_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282666</th>\n",
       "      <td>4478067.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347238</th>\n",
       "      <td>5272331.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157205</th>\n",
       "      <td>2935625.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39564</th>\n",
       "      <td>1486933.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306310</th>\n",
       "      <td>4769321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73349</th>\n",
       "      <td>1902237.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371403</th>\n",
       "      <td>5568983.0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312201</th>\n",
       "      <td>4841806.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267336</th>\n",
       "      <td>4289713.0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>2576633.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244992 rows × 638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        eid_correct  Inferred_Gender  Age X1.8495945_T_C_C X1.20149058_A_G_G   \n",
       "282666    4478067.0                1   66                1                 0  \\\n",
       "347238    5272331.0                0   64                0                 0   \n",
       "157205    2935625.0                1   44                1                 1   \n",
       "39564     1486933.0                0   56                0                 0   \n",
       "306310    4769321.0                1   51                2                 0   \n",
       "...             ...              ...  ...              ...               ...   \n",
       "73349     1902237.0                1   52                2                 0   \n",
       "371403    5568983.0                1   61                1                 0   \n",
       "312201    4841806.0                1   62                0                 0   \n",
       "267336    4289713.0                1   63                0                 0   \n",
       "128037    2576633.0                0   45                1                 1   \n",
       "\n",
       "       X1.20149560_G_A_A X1.20150839_A_G_G X1.20150984_C_G_G   \n",
       "282666                 0                 0                 0  \\\n",
       "347238                 0                 0                 0   \n",
       "157205                 1                 1                 1   \n",
       "39564                  0                 0                 0   \n",
       "306310                 0                 0                 0   \n",
       "...                  ...               ...               ...   \n",
       "73349                  0                 0                 0   \n",
       "371403                 0                 0                 0   \n",
       "312201                 0                 0                 0   \n",
       "267336                 0                 0                 0   \n",
       "128037                 1                 1                 1   \n",
       "\n",
       "       X1.20150998_A_G_G X1.20151290_C_A_A  ... X21.38740824_A_G_G   \n",
       "282666                 0                 0  ...                  0  \\\n",
       "347238                 0                 0  ...                  0   \n",
       "157205                 1                 1  ...                  1   \n",
       "39564                  0                 0  ...                  0   \n",
       "306310                 0                 0  ...                  0   \n",
       "...                  ...               ...  ...                ...   \n",
       "73349                  0                 0  ...                  0   \n",
       "371403                 0                 0  ...                  0   \n",
       "312201                 0                 0  ...                  2   \n",
       "267336                 0                 0  ...                  1   \n",
       "128037                 1                 1  ...                  0   \n",
       "\n",
       "       X21.39972727_C_A_A  X21.44357419_T_G_T X22.22599537_G_A_A   \n",
       "282666                  2                   1                  0  \\\n",
       "347238                  1                   0                  0   \n",
       "157205                  1                   2                  0   \n",
       "39564                   1                   2                  0   \n",
       "306310                  2                   1                  0   \n",
       "...                   ...                 ...                ...   \n",
       "73349                   0                   2                  1   \n",
       "371403                  2                   1                  0   \n",
       "312201                  2                   2                  0   \n",
       "267336                  1                   0                  0   \n",
       "128037                  0                   1                  0   \n",
       "\n",
       "        X22.29656431_C_T_T X22.39738425_A_C_A X22.39738501_G_C_G   \n",
       "282666                   0                  1                  1  \\\n",
       "347238                   0                  0                  0   \n",
       "157205                   0                  1                  1   \n",
       "39564                    0                  0                  0   \n",
       "306310                   0                  1                  1   \n",
       "...                    ...                ...                ...   \n",
       "73349                    0                  0                  0   \n",
       "371403                   0                  0                  0   \n",
       "312201                   0                  0                  0   \n",
       "267336                   0                  1                  1   \n",
       "128037                   0                  0                  0   \n",
       "\n",
       "       X22.39743170_G_T_G X22.39758541_A_G_A  X22.39758881_A_G_A  \n",
       "282666                  0                  0                   0  \n",
       "347238                  0                  0                   0  \n",
       "157205                  1                  0                   0  \n",
       "39564                   0                  0                   0  \n",
       "306310                  1                  1                   1  \n",
       "...                   ...                ...                 ...  \n",
       "73349                   0                  0                   0  \n",
       "371403                  0                  0                   0  \n",
       "312201                  0                  0                   0  \n",
       "267336                  2                  1                   1  \n",
       "128037                  0                  0                   0  \n",
       "\n",
       "[244992 rows x 638 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP EID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.718959 using {'C': 0.01, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.706528 (0.006394) with: {'C': 100, 'max_iter': 400, 'solver': 'lbfgs'}\n",
      "0.709104 (0.006923) with: {'C': 100, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.710549 (0.006265) with: {'C': 100, 'max_iter': 600, 'solver': 'lbfgs'}\n",
      "0.711011 (0.005629) with: {'C': 100, 'max_iter': 700, 'solver': 'lbfgs'}\n",
      "0.710141 (0.004638) with: {'C': 100, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.707898 (0.004480) with: {'C': 100, 'max_iter': 1200, 'solver': 'lbfgs'}\n",
      "0.704513 (0.008419) with: {'C': 10, 'max_iter': 400, 'solver': 'lbfgs'}\n",
      "0.708567 (0.006126) with: {'C': 10, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.710117 (0.006010) with: {'C': 10, 'max_iter': 600, 'solver': 'lbfgs'}\n",
      "0.710857 (0.005863) with: {'C': 10, 'max_iter': 700, 'solver': 'lbfgs'}\n",
      "0.710413 (0.004276) with: {'C': 10, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.708102 (0.004591) with: {'C': 10, 'max_iter': 1200, 'solver': 'lbfgs'}\n",
      "0.705432 (0.006601) with: {'C': 1.0, 'max_iter': 400, 'solver': 'lbfgs'}\n",
      "0.709036 (0.006473) with: {'C': 1.0, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.710157 (0.006320) with: {'C': 1.0, 'max_iter': 600, 'solver': 'lbfgs'}\n",
      "0.711078 (0.005701) with: {'C': 1.0, 'max_iter': 700, 'solver': 'lbfgs'}\n",
      "0.710603 (0.004663) with: {'C': 1.0, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.708790 (0.004349) with: {'C': 1.0, 'max_iter': 1200, 'solver': 'lbfgs'}\n",
      "0.706293 (0.005539) with: {'C': 0.1, 'max_iter': 400, 'solver': 'lbfgs'}\n",
      "0.709242 (0.006188) with: {'C': 0.1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.710830 (0.005539) with: {'C': 0.1, 'max_iter': 600, 'solver': 'lbfgs'}\n",
      "0.711937 (0.005676) with: {'C': 0.1, 'max_iter': 700, 'solver': 'lbfgs'}\n",
      "0.712527 (0.005488) with: {'C': 0.1, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.712163 (0.005560) with: {'C': 0.1, 'max_iter': 1200, 'solver': 'lbfgs'}\n",
      "0.715888 (0.007596) with: {'C': 0.01, 'max_iter': 400, 'solver': 'lbfgs'}\n",
      "0.717960 (0.006308) with: {'C': 0.01, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.718493 (0.006169) with: {'C': 0.01, 'max_iter': 600, 'solver': 'lbfgs'}\n",
      "0.718818 (0.006030) with: {'C': 0.01, 'max_iter': 700, 'solver': 'lbfgs'}\n",
      "0.718959 (0.006018) with: {'C': 0.01, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.718959 (0.006018) with: {'C': 0.01, 'max_iter': 1200, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "logistic_search = LogisticRegression(class_weight=\"balanced\")\n",
    "solvers = ['lbfgs']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "iter = [400, 500, 600, 700, 1000, 1200]\n",
    "grid = dict(solver=solvers,C=c_values, max_iter=iter)\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=logistic_search, param_grid=grid, cv=cv, scoring='roc_auc',error_score=0)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fayzan/opt/anaconda3/envs/PGS/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, class_weight=&#x27;balanced&#x27;, max_iter=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, class_weight=&#x27;balanced&#x27;, max_iter=400)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', max_iter=400)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(class_weight=\"balanced\",C=0.01, max_iter=400, solver='lbfgs')\n",
    "classifier.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC ROC for Test Set is 66.55424348091789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "test_acc = sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
    "print(\"The AUC ROC for Test Set is {}\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 36.72222222222221, 'Predicted Values')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm, annot=True,fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.xlabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = tn / (tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens = tp / (tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763984707459129"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6546863988724454"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#classifier1 = RandomForestClassifier()\n",
    "#classifier1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.metrics\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#import seaborn as sns\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#y_pred = classifier1.predict(x_test)\n",
    "#test_acc = sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
    "#print(\"The Accuracy for Test Set is {}\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Try autoencoder for snps\n",
    "#import shap\n",
    "# Fits the explainer\n",
    "#explainer = shap.Explainer(classifier.predict, x_test)\n",
    "# Calculates the SHAP values - It takes some time\n",
    "#shap_values = explainer(x_test, max_evals=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SHAP values\n",
    "#shap_values = explainer.shap_values(X)\n",
    "#shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = np.load('columns.csv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.append(b, \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Age', 'Inferred_Gender', 'X1.108176287_C_T_T',\n",
       "       'X1.151115007_G_A_A', 'X1.154837939_A_G_G', 'X1.155026114_C_T_C',\n",
       "       'X1.155033317_T_C_T', 'X1.155033918_C_T_T', 'X1.155034632_C_G_G',\n",
       "       'X1.155044197_T_G_G', 'X1.155074903_G_T_G', 'X1.155076043_C_T_C',\n",
       "       'X1.155076505_A_G_A', 'X1.155076734_C_T_C', 'X1.155080090_A_G_A',\n",
       "       'X1.155081940_T_C_T', 'X1.155082298_T_C_T', 'X1.155083942_T_C_T',\n",
       "       'X1.155097562_C_G_G', 'X1.155198771_A_G_G', 'X1.160742649_C_T_C',\n",
       "       'X1.160742850_A_G_A', 'X1.160970089_C_T_T', 'X1.161389646_G_A_A',\n",
       "       'X1.161452866_G_T_T', 'X1.161468430_C_T_T', 'X1.171719769_C_T_T',\n",
       "       'X1.171863472_T_G_G', 'X1.183517524_T_C_C', 'X1.20149058_A_G_G',\n",
       "       'X1.20149560_G_A_A', 'X1.20150839_A_G_G', 'X1.20150984_C_G_G',\n",
       "       'X1.20150998_A_G_G', 'X1.20151290_C_A_A', 'X1.20151431_A_G_G',\n",
       "       'X1.20151939_G_C_C', 'X1.20155678_C_T_T', 'X1.20157585_A_T_T',\n",
       "       'X1.20158241_T_C_C', 'X1.20158604_T_G_G', 'X1.20159225_T_A_A',\n",
       "       'X1.205723572_C_T_C', 'X1.226797733_G_A_A', 'X1.226916078_T_C_C',\n",
       "       'X1.22726564_A_G_G', 'X1.22728093_G_A_A', 'X1.232664611_C_T_T',\n",
       "       'X1.75965414_G_C_G', 'X1.8495945_T_C_C', 'X1.90992380_C_T_T',\n",
       "       'X1.92790752_C_T_T', 'X1.93837133_T_C_T', 'X10.103550281_G_T_T',\n",
       "       'X10.103940629_G_A_A', 'X10.104015279_A_G_G',\n",
       "       'X10.104606615_T_C_C', 'X10.121361986_C_T_T',\n",
       "       'X10.121536327_G_A_A', 'X10.121679013_A_G_A',\n",
       "       'X10.121842595_G_A_A', 'X10.123842523_G_A_A',\n",
       "       'X10.123846288_G_A_A', 'X10.126502854_C_T_T',\n",
       "       'X10.132926408_G_A_A', 'X10.15563450_C_T_C', 'X10.2766921_G_A_G',\n",
       "       'X10.35533707_G_A_A', 'X10.35557933_C_T_T', 'X10.35559567_T_C_C',\n",
       "       'X10.35563776_T_G_G', 'X10.35565071_C_T_T', 'X10.35612545_G_A_A',\n",
       "       'X10.35662791_C_T_T', 'X10.35668587_T_A_A', 'X10.35668965_C_T_T',\n",
       "       'X10.35678983_C_T_T', 'X10.35704802_G_A_A', 'X10.35709240_G_A_A',\n",
       "       'X10.35715413_T_A_A', 'X10.35733661_A_T_T', 'X10.35747724_C_A_A',\n",
       "       'X10.35750374_A_C_C', 'X10.35761414_T_C_C', 'X10.35779999_G_A_A',\n",
       "       'X10.35785779_C_T_T', 'X10.35789417_G_A_A', 'X10.35792410_C_G_G',\n",
       "       'X10.35840750_A_T_T', 'X10.35853425_A_G_G', 'X10.35873777_A_G_G',\n",
       "       'X10.46121886_C_T_T', 'X10.50821191_G_T_G', 'X10.54879218_A_G_G',\n",
       "       'X10.54880387_A_C_C', 'X10.56689984_G_T_T', 'X10.6081462_A_G_G',\n",
       "       'X10.6092989_C_T_T', 'X10.6094679_G_A_A', 'X10.6101524_G_A_A',\n",
       "       'X10.6183814_G_A_A', 'X10.6632290_G_A_A', 'X10.71062880_A_C_A',\n",
       "       'X10.78157572_T_C_C', 'X10.8011423_A_C_C', 'X10.90027875_G_A_A',\n",
       "       'X11.108138003_T_C_C', 'X11.10820384_A_C_A', 'X11.118620697_T_C_C',\n",
       "       'X11.124180643_G_T_T', 'X11.2200949_A_G_A', 'X11.3700876_C_T_T',\n",
       "       'X11.549119_T_G_T', 'X11.5895414_T_C_C', 'X11.60835596_C_T_C',\n",
       "       'X11.6341684_C_G_C', 'X11.63806993_C_T_T', 'X11.71807767_A_C_C',\n",
       "       'X11.93561149_G_A_A', 'X12.116457090_C_T_T', 'X12.117175608_C_T_T',\n",
       "       'X12.123326598_G_T_T', 'X12.123345509_G_T_T',\n",
       "       'X12.123585705_C_T_T', 'X12.124134802_C_T_T',\n",
       "       'X12.130992170_A_G_G', 'X12.133063768_G_A_A',\n",
       "       'X12.133257837_C_A_A', 'X12.21418143_C_T_T', 'X12.40380035_G_A_A',\n",
       "       'X12.40388109_C_T_T', 'X12.40575173_C_T_T', 'X12.40614434_C_T_T',\n",
       "       'X12.40614656_A_G_A', 'X12.40698422_C_T_T', 'X12.40707861_C_T_T',\n",
       "       'X12.40713899_T_C_C', 'X12.40753796_T_C_C', 'X12.40829565_G_A_A',\n",
       "       'X12.41006567_T_C_C', 'X12.41251554_A_G_G', 'X12.49472965_G_A_A',\n",
       "       'X12.54023491_G_A_A', 'X12.57848639_G_A_G', 'X12.6423900_A_G_G',\n",
       "       'X12.72179446_C_T_T', 'X12.78636050_T_C_T', 'X13.103345465_T_C_C',\n",
       "       'X13.113530199_G_A_A', 'X13.20767957_G_T_G', 'X13.46594619_T_C_C',\n",
       "       'X13.49927732_T_C_C', 'X13.60545105_G_T_T', 'X13.86229641_T_C_T',\n",
       "       'X13.97865021_T_C_T', 'X13.98139677_T_C_T', 'X14.101979288_G_A_A',\n",
       "       'X14.104399640_G_A_A', 'X14.105623612_T_C_T', 'X14.25880510_A_C_A',\n",
       "       'X14.25887879_G_A_A', 'X14.47246378_C_T_C', 'X14.55348869_C_T_T',\n",
       "       'X14.56191413_C_T_T', 'X14.63098431_A_G_A', 'X14.74976452_C_T_T',\n",
       "       'X14.88472612_C_T_T', 'X14.88620757_G_A_A', 'X15.41798614_T_C_C',\n",
       "       'X15.63348087_A_G_A', 'X15.72189952_T_A_A', 'X15.76017452_C_T_T',\n",
       "       'X15.98512431_C_T_T', 'X15.98876029_G_C_C', 'X16.11002927_A_G_A',\n",
       "       'X16.11151228_C_T_T', 'X16.11174365_G_A_A', 'X16.11231857_G_A_A',\n",
       "       'X16.12060163_A_G_A', 'X16.19279380_T_C_T', 'X16.28513827_A_G_G',\n",
       "       'X16.28515228_A_C_C', 'X16.28519693_G_A_A', 'X16.28523248_G_A_A',\n",
       "       'X16.28566158_G_T_T', 'X16.28622480_T_C_C', 'X16.28838018_T_C_C',\n",
       "       'X16.28843327_C_G_G', 'X16.28861624_G_C_C', 'X16.28985450_C_T_T',\n",
       "       'X16.30471109_T_C_T', 'X16.30482494_T_C_T', 'X16.30485393_G_C_G',\n",
       "       'X16.30493881_T_C_T', 'X16.30495412_T_C_T', 'X16.30495496_C_T_T',\n",
       "       'X16.30500985_A_G_A', 'X16.30510571_C_T_T', 'X16.30520856_C_T_T',\n",
       "       'X16.30553899_A_G_G', 'X16.31004169_T_C_C', 'X16.31370452_C_T_C',\n",
       "       'X16.50736656_A_G_G', 'X16.52636242_C_A_A', 'X16.68600595_A_G_G',\n",
       "       'X16.68628543_A_C_C', 'X16.68638730_G_A_A', 'X16.82455819_T_C_C',\n",
       "       'X16.82637134_A_G_G', 'X16.88909159_G_T_T', 'X16.89986117_C_T_T',\n",
       "       'X17.16203290_C_A_A', 'X17.18003845_C_T_C', 'X17.18063441_T_C_T',\n",
       "       'X17.40741013_T_C_C', 'X17.42786711_G_A_A', 'X17.42929985_G_T_T',\n",
       "       'X17.43060768_T_G_G', 'X17.43417273_G_T_T', 'X17.43472507_A_G_G',\n",
       "       'X17.43744203_C_T_T', 'X17.43784228_T_C_T', 'X17.43935838_T_C_T',\n",
       "       'X17.43993376_T_G_G', 'X17.44019712_G_A_A', 'X17.44071851_G_A_A',\n",
       "       'X17.44189067_A_G_G', 'X17.44981466_T_C_C', 'X17.60188441_G_A_A',\n",
       "       'X17.61666687_C_T_T', 'X17.64141919_T_A_A', 'X17.72725478_C_G_G',\n",
       "       'X18.33102339_T_C_C', 'X18.40628467_T_C_T', 'X18.40673380_A_G_G',\n",
       "       'X18.60985879_T_C_C', 'X18.67950442_T_G_G', 'X19.2322165_G_A_A',\n",
       "       'X19.46304585_G_T_T', 'X19.47615835_C_T_T', 'X19.54753126_G_C_C',\n",
       "       'X2.102570469_G_A_A', 'X2.102576880_G_C_C', 'X2.102638615_C_T_T',\n",
       "       'X2.111854524_C_T_T', 'X2.135443940_A_G_G', 'X2.135803425_G_T_G',\n",
       "       'X2.135925002_T_G_G', 'X2.164451154_C_T_T', 'X2.169161223_C_T_C',\n",
       "       'X2.170964822_T_G_G', 'X2.170965121_G_A_A', 'X2.170966684_G_A_G',\n",
       "       'X2.181890819_C_T_T', 'X2.183616913_A_C_C', 'X2.191364828_C_T_T',\n",
       "       'X2.201253956_A_G_G', 'X2.218816702_C_T_T', 'X2.227853157_G_A_A',\n",
       "       'X2.234143062_C_T_T', 'X2.236943672_C_T_C', 'X2.239323169_A_G_A',\n",
       "       'X2.241652703_T_C_C', 'X2.241653287_A_G_G', 'X2.26191490_G_A_A',\n",
       "       'X2.31832807_T_C_T', 'X2.32503526_T_C_T', 'X2.32811909_A_G_A',\n",
       "       'X2.33246146_G_A_A', 'X2.38537579_T_C_C', 'X2.61763207_T_C_T',\n",
       "       'X20.25275266_T_C_C', 'X20.25539937_C_T_T', 'X20.25672987_G_A_A',\n",
       "       'X20.26182690_A_G_G', 'X20.2828596_A_G_G', 'X20.3164686_T_C_C',\n",
       "       'X20.31877713_A_T_T', 'X20.40904924_C_T_T', 'X20.43207483_A_T_T',\n",
       "       'X20.48618781_C_T_T', 'X20.62294447_G_A_A', 'X21.16812882_C_T_T',\n",
       "       'X21.38740824_A_G_G', 'X21.39972727_C_A_A', 'X22.29656431_C_T_T',\n",
       "       'X22.39738425_A_C_A', 'X22.39738501_G_C_G', 'X22.39743170_G_T_G',\n",
       "       'X22.39758541_A_G_A', 'X22.39758881_A_G_A', 'X3.160812752_C_T_T',\n",
       "       'X3.163861651_A_G_A', 'X3.163915341_A_G_A', 'X3.176417139_G_A_A',\n",
       "       'X3.176423123_A_G_G', 'X3.182760073_T_G_G', 'X3.18361759_A_C_C',\n",
       "       'X3.185834290_T_C_T', 'X3.18674261_C_T_T', 'X3.197701913_G_T_T',\n",
       "       'X3.28700178_A_G_A', 'X3.29629760_C_T_T', 'X3.39307162_G_A_A',\n",
       "       'X3.46141902_T_C_T', 'X3.48748989_G_T_G', 'X3.49162583_C_T_T',\n",
       "       'X3.49450137_C_A_A', 'X3.49463700_C_T_T', 'X3.49568181_G_A_A',\n",
       "       'X3.49740895_A_G_G', 'X3.50154223_T_C_C', 'X3.51929183_C_T_T',\n",
       "       'X3.52261031_A_G_G', 'X3.58292485_G_A_A', 'X3.64634411_T_C_C',\n",
       "       'X3.64636128_G_A_A', 'X4.1008212_C_T_T', 'X4.1024287_T_C_C',\n",
       "       'X4.102753817_G_A_A', 'X4.102920373_T_C_C', 'X4.102926923_G_A_A',\n",
       "       'X4.103188709_C_T_T', 'X4.114369065_C_T_T', 'X4.114447191_G_A_G',\n",
       "       'X4.122979432_C_T_T', 'X4.124770865_A_G_G', 'X4.1312394_C_T_T',\n",
       "       'X4.14167196_A_G_G', 'X4.15737348_G_A_G', 'X4.15751051_G_A_A',\n",
       "       'X4.15753687_A_G_G', 'X4.15777881_C_T_C', 'X4.15794069_G_A_G',\n",
       "       'X4.15796333_A_G_A', 'X4.15829612_A_G_A', 'X4.15833532_A_G_A',\n",
       "       'X4.15840839_A_G_A', 'X4.17953590_A_G_G', 'X4.2451467_G_A_A',\n",
       "       'X4.47221089_T_G_G', 'X4.56820412_G_A_A', 'X4.749620_T_G_G',\n",
       "       'X4.77076710_G_A_A', 'X4.77100807_T_C_C', 'X4.77147969_A_G_G',\n",
       "       'X4.77198054_C_T_T', 'X4.77222933_A_C_A', 'X4.831852_A_C_C',\n",
       "       'X4.88533540_A_T_T', 'X4.88732874_A_G_G', 'X4.90205253_C_A_C',\n",
       "       'X4.90368545_G_A_A', 'X4.90412435_A_G_G', 'X4.90441114_T_C_C',\n",
       "       'X4.90513701_G_A_A', 'X4.90579508_G_A_A', 'X4.90594987_G_A_A',\n",
       "       'X4.90619032_C_T_T', 'X4.90624593_T_C_C', 'X4.90700329_T_C_C',\n",
       "       'X4.90757294_A_C_A', 'X4.90788943_G_A_A', 'X4.90882543_C_T_T',\n",
       "       'X4.90982912_A_G_G', 'X4.91057794_A_G_G', 'X4.91164040_C_T_T',\n",
       "       'X4.94159851_G_T_T', 'X4.951947_T_C_C', 'X4.96372611_C_T_T',\n",
       "       'X5.102363402_C_T_C', 'X5.102660400_T_C_C', 'X5.131680264_G_A_A',\n",
       "       'X5.132754003_A_G_A', 'X5.133924478_T_C_C', 'X5.134199105_C_A_A',\n",
       "       'X5.141605252_T_C_C', 'X5.141605948_T_C_C', 'X5.149784414_C_T_T',\n",
       "       'X5.36000291_C_T_T', 'X5.55250727_A_G_G', 'X5.55436316_T_C_C',\n",
       "       'X5.60297500_A_G_A', 'X5.79846926_T_C_C', 'X5.87513775_C_T_C',\n",
       "       'X5.96223552_G_A_A', 'X6.111829239_A_G_A', 'X6.112138882_G_A_A',\n",
       "       'X6.112150430_A_G_G', 'X6.112164313_G_A_A', 'X6.119396266_T_C_C',\n",
       "       'X6.126249914_T_G_G', 'X6.159340625_G_T_T', 'X6.16007218_C_A_A',\n",
       "       'X6.167355916_A_G_G', 'X6.168625719_G_A_A', 'X6.170143300_A_G_G',\n",
       "       'X6.18130918_T_C_C', 'X6.18139228_C_T_T', 'X6.24399181_A_C_C',\n",
       "       'X6.27299567_T_C_C', 'X6.27681215_G_A_A', 'X6.28037020_G_T_T',\n",
       "       'X6.28054198_A_G_G', 'X6.29723674_T_C_C', 'X6.30109861_A_C_C',\n",
       "       'X6.30241114_A_G_G', 'X6.30280125_A_C_C', 'X6.30281402_G_C_C',\n",
       "       'X6.30286729_C_T_T', 'X6.30292083_T_C_C', 'X6.30309105_G_A_A',\n",
       "       'X6.30376864_A_G_G', 'X6.30383768_A_G_G', 'X6.30632655_T_C_C',\n",
       "       'X6.30739904_G_A_A', 'X6.31063413_T_C_T', 'X6.31173433_G_A_A',\n",
       "       'X6.31184949_G_A_A', 'X6.31352631_A_G_G', 'X6.31378510_G_A_A',\n",
       "       'X6.31378714_A_T_T', 'X6.31379109_G_A_A', 'X6.31382147_G_C_C',\n",
       "       'X6.31382882_C_A_A', 'X6.31383108_T_C_C', 'X6.31384792_T_C_C',\n",
       "       'X6.31388277_C_T_T', 'X6.31390055_G_T_T', 'X6.31407643_T_C_C',\n",
       "       'X6.31407821_A_T_T', 'X6.31412513_G_C_C', 'X6.31431820_C_T_T',\n",
       "       'X6.31590354_G_A_G', 'X6.31846234_A_G_A', 'X6.31915614_G_A_A',\n",
       "       'X6.31920873_C_T_T', 'X6.32109938_G_T_T', 'X6.32213052_A_T_T',\n",
       "       'X6.32219320_G_T_T', 'X6.32221552_G_A_G', 'X6.32230354_A_G_A',\n",
       "       'X6.32257284_T_G_G', 'X6.32282854_A_G_G', 'X6.32303848_G_A_A',\n",
       "       'X6.32333341_A_G_G', 'X6.32341318_A_G_G', 'X6.32341473_T_C_C',\n",
       "       'X6.32341719_C_T_T', 'X6.32342087_C_T_T', 'X6.32342129_C_T_T',\n",
       "       'X6.32343095_T_C_C', 'X6.32343096_G_A_A', 'X6.32343882_C_T_T',\n",
       "       'X6.32344973_G_T_T', 'X6.32345052_A_G_G', 'X6.32347490_C_T_T',\n",
       "       'X6.32347532_C_T_T', 'X6.32349946_C_A_A', 'X6.32350036_A_G_G',\n",
       "       'X6.32350384_C_A_A', 'X6.32350776_G_A_A', 'X6.32350868_A_C_C',\n",
       "       'X6.32351283_T_C_C', 'X6.32354428_A_G_G', 'X6.32355605_G_A_A',\n",
       "       'X6.32355683_A_G_G', 'X6.32357165_T_C_C', 'X6.32358231_C_T_T',\n",
       "       'X6.32358942_T_A_A', 'X6.32359121_G_A_A', 'X6.32363844_C_T_T',\n",
       "       'X6.32364356_A_G_G', 'X6.32367777_A_T_T', 'X6.32367847_T_C_C',\n",
       "       'X6.32371179_G_C_C', 'X6.32371619_A_G_G', 'X6.32374622_A_T_T',\n",
       "       'X6.32375352_A_C_C', 'X6.32375424_G_A_A', 'X6.32375695_G_A_A',\n",
       "       'X6.32376176_C_T_T', 'X6.32376746_C_T_T', 'X6.32378945_T_A_A',\n",
       "       'X6.32379489_C_T_T', 'X6.32409530_G_A_G', 'X6.32410576_T_C_T',\n",
       "       'X6.32411035_A_C_A', 'X6.32428115_G_A_A', 'X6.32428715_G_A_A',\n",
       "       'X6.32669817_T_C_C', 'X6.32682862_C_T_T', 'X6.32733823_C_T_T',\n",
       "       'X6.32804798_G_A_A', 'X6.32861920_A_G_G', 'X6.32950382_T_C_C',\n",
       "       'X6.412802_G_A_G', 'X6.46184459_A_G_G', 'X6.51159995_G_A_A',\n",
       "       'X6.54254589_A_C_C', 'X6.6736557_C_T_T', 'X6.72487762_C_T_T',\n",
       "       'X6.79745107_C_T_C', 'X7.102743893_C_T_C', 'X7.129663496_C_T_T',\n",
       "       'X7.157932055_C_T_T', 'X7.23430418_C_T_T', 'X7.28128002_T_C_C',\n",
       "       'X7.30606700_C_T_T', 'X7.50430493_T_A_A', 'X7.50430769_G_C_C',\n",
       "       'X7.50439198_G_A_A', 'X7.51123343_T_C_T', 'X8.10999583_C_T_T',\n",
       "       'X8.110371435_A_G_G', 'X8.121298156_G_C_C', 'X8.126526686_T_C_C',\n",
       "       'X8.138905296_A_G_A', 'X8.17510766_C_G_G', 'X8.17541943_T_G_G',\n",
       "       'X8.27466315_T_C_T', 'X8.56824771_C_G_C', 'X8.6783479_C_T_T',\n",
       "       'X8.68561738_T_A_A', 'X8.94792887_G_A_A', 'X9.138642022_G_A_A',\n",
       "       'X9.139150738_G_A_A', 'X9.139151148_G_T_T', 'X9.139153375_G_A_A',\n",
       "       'X9.139153592_C_T_T', 'X9.139219709_G_T_T', 'X9.139336813_T_G_G',\n",
       "       'X9.17579690_T_G_T', 'X9.17726888_C_T_T', 'X9.33778399_G_A_G',\n",
       "       'X9.34046391_C_T_C', 'X9.5023192_A_G_G', 'X9.5065003_C_G_G',\n",
       "       'X9.86258685_A_C_C', 'X9.86945961_A_C_C', 'X9.89056018_A_G_G',\n",
       "       'X9.89059858_G_A_A', 'X9.93256092_T_C_T', 'eid_correct', 'Y'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in ppmi data\n",
    "ppmi = pyreadr.read_r('/Users/fayzan/PycharmProjects/PGS/Data/ppmialignedtoukbiogwas.rds')\n",
    "ppmi1 = ppmi[None]\n",
    "ppmi1.rename(columns = {'gen':'Inferred_Gender', 'age':'Age', 'APPRDX':'Y', \"PATNO\":\"eid_correct\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid_correct</th>\n",
       "      <th>Age</th>\n",
       "      <th>Inferred_Gender</th>\n",
       "      <th>Y</th>\n",
       "      <th>FID</th>\n",
       "      <th>PAT</th>\n",
       "      <th>MAT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PHENOTYPE</th>\n",
       "      <th>X1.8495945_T_C_C</th>\n",
       "      <th>...</th>\n",
       "      <th>X20.62294447_G_A_A</th>\n",
       "      <th>X21.16812882_C_T_T</th>\n",
       "      <th>X21.38740824_A_G_G</th>\n",
       "      <th>X21.39972727_C_A_A</th>\n",
       "      <th>X22.29656431_C_T_T</th>\n",
       "      <th>X22.39738425_A_C_A</th>\n",
       "      <th>X22.39738501_G_C_G</th>\n",
       "      <th>X22.39743170_G_T_G</th>\n",
       "      <th>X22.39758541_A_G_A</th>\n",
       "      <th>X22.39758881_A_G_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>69.139726</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001.0</td>\n",
       "      <td>65.142466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3002.0</td>\n",
       "      <td>67.578082</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3003.0</td>\n",
       "      <td>56.717808</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004.0</td>\n",
       "      <td>59.413699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>4124.0</td>\n",
       "      <td>71.117808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>4125.0</td>\n",
       "      <td>64.019178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>4126.0</td>\n",
       "      <td>55.734247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>4136.0</td>\n",
       "      <td>55.764384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>4139.0</td>\n",
       "      <td>80.924231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429 rows × 550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     eid_correct        Age  Inferred_Gender    Y   FID  PAT  MAT  SEX   \n",
       "0         3000.0  69.139726              2.0  2.0  3000    0    0    2  \\\n",
       "1         3001.0  65.142466              1.0  1.0  3001    0    0    1   \n",
       "2         3002.0  67.578082              2.0  1.0  3002    0    0    2   \n",
       "3         3003.0  56.717808              2.0  1.0  3003    0    0    2   \n",
       "4         3004.0  59.413699              1.0  2.0  3004    0    0    1   \n",
       "..           ...        ...              ...  ...   ...  ...  ...  ...   \n",
       "424       4124.0  71.117808              1.0  1.0  4124    0    0    1   \n",
       "425       4125.0  64.019178              1.0  1.0  4125    0    0    1   \n",
       "426       4126.0  55.734247              1.0  1.0  4126    0    0    1   \n",
       "427       4136.0  55.764384              1.0  1.0  4136    0    0    1   \n",
       "428       4139.0  80.924231              1.0  2.0  4139    0    0    1   \n",
       "\n",
       "     PHENOTYPE X1.8495945_T_C_C  ... X20.62294447_G_A_A X21.16812882_C_T_T   \n",
       "0           -9                1  ...                  0                  2  \\\n",
       "1           -9                0  ...                  0                  1   \n",
       "2           -9                1  ...                  0                  1   \n",
       "3           -9                1  ...                  0                  1   \n",
       "4           -9                1  ...                  1                  1   \n",
       "..         ...              ...  ...                ...                ...   \n",
       "424         -9                2  ...                  0                  0   \n",
       "425         -9                2  ...                  0                  0   \n",
       "426         -9                1  ...                  0                  2   \n",
       "427         -9                0  ...                  0                  1   \n",
       "428         -9                1  ...                  0                  1   \n",
       "\n",
       "    X21.38740824_A_G_G X21.39972727_C_A_A X22.29656431_C_T_T   \n",
       "0                    0                  1                  0  \\\n",
       "1                    0                  1                  0   \n",
       "2                    2                  0                  0   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                    1                  1                  0   \n",
       "..                 ...                ...                ...   \n",
       "424                  1                  0                  0   \n",
       "425                  1                  1                  0   \n",
       "426                  0                  1                  0   \n",
       "427                  0                  1                  0   \n",
       "428                  1                  0                  0   \n",
       "\n",
       "    X22.39738425_A_C_A X22.39738501_G_C_G X22.39743170_G_T_G   \n",
       "0                    0                  0                  0  \\\n",
       "1                    1                  1                  1   \n",
       "2                    0                  0                  0   \n",
       "3                    2                  2                  2   \n",
       "4                    1                  1                  1   \n",
       "..                 ...                ...                ...   \n",
       "424                  2                  2                  2   \n",
       "425                  0                  0                  0   \n",
       "426                  1                  1                  1   \n",
       "427                  0                  0                  0   \n",
       "428                  0                  0                  0   \n",
       "\n",
       "    X22.39758541_A_G_A X22.39758881_A_G_A  \n",
       "0                    0                  0  \n",
       "1                    0                  0  \n",
       "2                    0                  0  \n",
       "3                    0                NaN  \n",
       "4                    1                  1  \n",
       "..                 ...                ...  \n",
       "424                  1                  1  \n",
       "425                  0                  0  \n",
       "426                  0                  0  \n",
       "427                  0                  1  \n",
       "428                  0                  0  \n",
       "\n",
       "[429 rows x 550 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in ppmi data\n",
    "\n",
    "#ppmi1\n",
    "ppmi2 = ppmi1[b]\n",
    "ppmi2\n",
    "#ppmi2['Y']\n",
    "ppmi2.loc[ppmi2[\"Y\"] == 2.0, \"Y\"] = 0.0  #recoded to match uk biobank\n",
    "\n",
    "\n",
    "ppmi2.loc[ppmi2[\"Inferred_Gender\"] == 2.0, \"Inferred_Gender\"] = 0.0\n",
    "\n",
    "X_val = ppmi2.iloc[:, :-1]\n",
    "\n",
    "#output\n",
    "Y_val = ppmi2.iloc[:, -1]\n",
    "\n",
    "X_val.fillna(X_val.mode().iloc[0], inplace=True)\n",
    "X_val.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP EID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC ROC for Test Set is 53.29822202300911\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = classifier.predict(X_val)\n",
    "test_acc = sklearn.metrics.roc_auc_score(Y_val, y_pred)\n",
    "print(\"The AUC ROC for Test Set is {}\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 36.72222222222221, 'Predicted Values')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA40AAAIhCAYAAADq/V8YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJk0lEQVR4nO3df3zN9f//8fuZORvm5/zIr5AQw7HQ3kLNj/xYKoS3H8lvC6OiN0YhS1LImymTScW7lh/9EHmjH1Q0GYZQm5/TRlsyxuzYdr5/9O183sf2mm2d42y6Xbu8Lm97vl7n+XqcdXlf3u+H+/P5eplsNptNAAAAAADkwsPdBQAAAAAAii6aRgAAAACAIZpGAAAAAIAhmkYAAAAAgCGaRgAAAACAIZpGAAAAAIAhmkYAAAAAgCGaRgAAAACAIZpGAACcwGazubsEAABcgqYRAIqZQ4cO6V//+pcCAwPVvHlzde7cWS+88IISEhJcds9Vq1apbdu2at68ud544w2nzBkdHa1GjRopOjraKfPl516NGjXSt99+m+s1x48ft19z9uzZfM9ttVr18ssva+PGjTe9tlGjRlqyZEm+5wYAoCigaQSAYmTNmjXq37+/fvvtN02aNElvvfWWRo8erT179qhPnz46duyY0++ZlpamefPmqXnz5oqMjFSvXr2cMq+fn5+ioqLk5+fnlPnyw8PDQ1u2bMn13ObNmws156+//qp33nlHmZmZN702KipKffv2LdR9AABwF5pGACgmYmJiNGfOHA0cOFArV67UI488ooCAAPXr10/vv/++vLy8NG3aNKffNzU1VdnZ2ercubNat26t6tWrO2VeHx8ftWjRQj4+Pk6ZLz/uvfdebdu2LdcGb/PmzWrcuLFL79+iRQvdcccdLr0HAADORtMIAMVEZGSkypYtq4kTJ+Y4V6lSJU2dOlWdOnXS1atXJUlZWVlas2aNHnnkETVv3lyBgYGaP3++MjIy7J+bOnWqhg4dqvXr16tr165q2rSpHnvsMe3cuVOStGHDBnXs2FGSNG3aNDVq1EiS1LFjR02dOtWhhg0bNjgs7bx27ZpmzZqlBx54QE2bNlW3bt0UGRlpvz635amHDh3SiBEjFBAQoHvvvVdPPfWU4uLicnxm9+7dGj58uCwWi9q2bavXXntNWVlZN/0dBgUF6eLFi/r+++8dxo8dO6ZTp06pe/fuOT6zfft2DRw4UP7+/vbvsWbNGknS2bNn1alTJ0lSaGio/Xc1depUDRkyRDNnztS9996roKAgZWVlOSxPDQkJUbNmzXTixAn7vZYsWaLGjRtrz549N/0uAADcKjSNAFAM2Gw2ffvtt2rTpo1KlSqV6zVBQUEaN26cSpcuLUmaMWOG5s6dq86dO+vNN9/UoEGDtHr1ao0dO9bhoS2HDx9WZGSkJkyYoKVLl6pEiRIaP368UlNTFRgYqPDwcEnSmDFjFBUVle+aX375Ze3cuVNTpkxRZGSkOnXqpFdffVXr16/P9frvv/9eAwYMsH/2pZdeUlJSkvr376/jx487XPvcc8+pZcuWWrZsmXr06KEVK1Zo7dq1N63p7rvvVoMGDXIsUd20aZPuu+8+ValSxWH866+/1rhx4+Tn56c33nhDS5YsUe3atTV79mzFxsaqatWqDr+fP/8sSXv37lVSUpKWLl2qSZMmqUSJEg5zz5o1S6VLl9bMmTMl/fHvYdmyZRo+fLjuu+++m34XAABuFU93FwAAuLnff/9dGRkZqlWrVr6uj4+P17p16zRp0iSNHj1aktS2bVtVrVpVkydP1s6dO/Xggw9Kki5fvqwNGzbozjvvlCSVLl1aTzzxhL7//nt17drVvmTzzjvvVIsWLfJd8549e9S2bVs9/PDDkqSAgACVLl1avr6+uV6/YMEC1alTR8uXL7c3WO3atdNDDz2kxYsX69///rf92r59+2rcuHGSpDZt2mj79u36+uuv1b9//5vW1b17d7377ruaNWuWPD3/+J/BzZs366mnnspxbXx8vHr16qXp06fbx/z9/RUQEKDo6GhZLBaH30+TJk3s12VmZmr27NmGy1ErV66smTNn6tlnn9XatWv1zjvvqGHDhnr66adv+h0AALiVSBoBoBj4s4nKzxJMSfbljX82bH96+OGHVaJECYcloZUqVbI3jJLsTU56evpfqjkgIEAffvihRo0apdWrVyshIUHjxo1TYGBgjmuvXr2qQ4cOqXv37g6JXLly5dShQ4ccyzX9/f0dfr7jjjvsy3Jv5sYlqrGxsTp//ry6dOmS49qRI0fqlVde0ZUrV3T48GFt3rxZERERkv54ampeKlSocNP9i0FBQeratatmzJihhIQEzZ8/X2azOV/fAwCAW4WmEQCKgfLly6tMmTJKTEw0vObq1atKTU2VJPt/3rjc0tPTUxUrVtTly5ftYzcudzWZTJKk7Ozsv1Tz9OnT9cwzz+js2bMKCwtT586d1b9//1yf8Hr58mXZbDZVrlw5x7nKlSs71CtJ3t7eDj97eHjk+z2J9erVU+PGje1LVDdv3qx27dqpfPnyOa69cOGCxo8fr1atWqlfv35asmSJ0tLSJN38vYxlypTJVz29evVSdna26tatq3r16uXrMwAA3Eo0jQBQTLRr107R0dEOD7L5Xx9++KH+8Y9/6Mcff7Q3QMnJyQ7XXL9+Xb///rsqVqz4l+u5MfW8Mekzm80aM2aMPv/8c3311Vf2NG3SpEk55ipbtqxMJpNSUlJynEtOTlaFChX+cr3/KygoSNu2bdP169e1ZcuWHInsn5577jkdOnRIq1at0oEDB/T555879Qm16enpmjt3rho2bKiff/5ZK1eudNrcAAA4C00jABQTw4cP18WLF7Vo0aIc55KTk7Vy5Urdfffd8vPzsz9IZdOmTQ7Xbdq0SVlZWWrZsuVfqsXHx0fnzp1zGIuJibH/+dq1a+ratau9CapRo4YGDRqkhx9+ONe0tHTp0mratKk+//xzh2b08uXL+vrrr/9yvTfq3r27Ll68qGXLlik1NdX+BNQbxcTEqEuXLgoICLAvG/3zybJ/JrE3PuCmIBYsWKBz585pyZIleuKJJ7R48eIcD/0BAMDdeBAOABQTLVq00NNPP61Fixbp+PHj6tmzpypWrKi4uDhFRkYqIyPD3lDefffd6tWrlxYvXqz09HS1bt1aR48eVXh4uAICAtS+ffu/VEuHDh0UERGhiIgIWSwWffnllw6vsfD29pafn5/Cw8NVsmRJNWrUSCdPntRHH32krl275jrnpEmTNGLECI0ePVoDBw7U9evXtXz5clmtVvtDb5yldu3aatasmSIiIvTQQw/Znzh7o+bNm2vjxo3y8/PTHXfcoX379mn58uUymUz2PZ9ly5aVJO3evVv169eXxWLJVw179uzR6tWr9eyzz6pu3bp65plntG3bNk2dOlUffPDBX2pGAQBwJppGAChGxowZoyZNmmjNmjV6+eWXlZqaqurVqyswMFBPPfWUqlevbr92zpw5qlOnjtavX6+33npLVatW1ZNPPqmxY8fKw+OvLTQJDg7WhQsXFBkZqevXryswMFBz5szRmDFj7NfMnj1bixYt0sqVK5WcnCxfX1/16dPH8Omgbdq00dtvv63Fixdr4sSJMpvNatWqlebNm6cGDRr8pXpzExQUpEOHDhkuTZWkV155RWFhYQoLC5Mk1a1bVy+++KI+/fRT7d27V9IfqeuwYcMUFRWlHTt26Lvvvrvpva9evarQ0FA1bNhQI0aMkPTHHsgZM2ZozJgxWrFihYKDg53wLQEA+OtMtvw+OQAAAAAA8LfDnkYAAAAAgCGaRgAAAACAIZpGAAAAAIAhmkYAAAAAgCGaRgAAAACAIZpGAAAAAIAhmkYAAAAAgCFPdxfgCtcy3V0BAMAZ4s+nubsEAIATNK3p4+4SCq2Uf4jL5k7fH+6yuZ2JpBEAAAAAYOi2TBoBAAAAwClM5Gw0jQAAAABgxGRydwVuR9sMAAAAADBE0ggAAAAARlieStIIAAAAADBG0ggAAAAARtjTSNIIAAAAADBG0ggAAAAARtjTSNIIAAAAADBG0ggAAAAARtjTSNMIAAAAAIZYnsryVAAAAACAMZJGAAAAADDC8lSSRgAAAACAMZJGAAAAADDCnkaSRgAAAACAMZJGAAAAADDCnkaSRgAAAACAMZJGAAAAADDCnkaaRgAAAAAwxPJUlqcCAAAAAIyRNAIAAACAEZankjQCAAAAAIyRNAIAAACAEZJGkkYAAAAAgDGSRgAAAAAw4sHTU0kaAQAAAACGSBoBAAAAwAh7GkkaAQAAAMCQyeS6oxCsVqt69Oih6Oho+9jevXvVu3dvtWjRQo899ph27drl8JnPPvtMnTt3lsVi0bhx43ThwoUC3ZOmEQAAAACKgYyMDE2cOFFxcXH2sd9++01PPfWUgoKCtHHjRnXv3l1jx47VuXPnJEkHDx7U9OnTFRISoqioKF26dEmhoaEFui9NIwAAAAAYMXm47iiA+Ph49evXT2fOnHEY37dvn0qUKKGRI0eqdu3aeuqpp+Tl5aUDBw5IklavXq3u3burZ8+euueee/Tqq69qx44dSkhIyPe9aRoBAAAAwA2sVqvS0tIcDqvVmuu1e/bsUUBAgKKiohzGK1SooIsXL2rr1q2y2Wzavn27rly5ooYNG0qSYmNj1apVK/v11atXV40aNRQbG5vvOnkQDgAAAAAYKeTew/yIiIhQeHi4w1hISIjGjx+f49qBAwfmOkerVq00aNAgTZgwQR4eHsrKytLcuXN11113SZJ+/fVXVa1a1eEzvr6+9uWr+UHTCAAAAABuEBwcrGHDhjmMmc3mAs1x5coVJSQkKCQkRB06dNDWrVv10ksvyWKxqH79+rp27VqOOc1ms2GimRuaRgAAAAAw4sJXbpjN5gI3iTdasWKFbDabQkJCJEl+fn46ePCg3n33Xb344ovy8vLK0SBarVaVKlUq3/dgTyMAAAAAFFM//vij7rnnHoexxo0bKzExUZJUrVo1paSkOJxPSUlRlSpV8n0PmkYAAAAAMFLE3tN4o6pVqyo+Pt5h7MSJE6pVq5YkyWKxKCYmxn4uKSlJSUlJslgs+b4Hy1MBAAAAwIgLl6c6Q9++fTVw4ECtWrVKnTp10hdffKFvv/1WH330kSRpwIABGjx4sFq0aKFmzZppzpw5CgwMVO3atfN9D5pGAAAAACimWrRooSVLlmjx4sX697//rXr16mn58uVq0KCBJMnf31+zZ8/W4sWLlZqaqrZt2yosLKxA9zDZbDabK4p3p2uZ7q4AAOAM8efT3F0CAMAJmtb0cXcJhVaq++sumzv982ddNrczFe2sFQAAAADgVixPBQAAAAAjRXxP463AbwAAAAAAYIikEQAAAACMOOnVGMUZSSMAAAAAwBBJIwAAAAAYYU8jTSMAAAAAGKJpZHkqAAAAAMAYSSMAAAAAGOFBOCSNAAAAAABjJI0AAAAAYIQ9jSSNAAAAAABjJI0AAAAAYIQ9jSSNAAAAAABjJI0AAAAAYIQ9jTSNAAAAAGCI5aksTwUAAAAAGCNpBAAAAAADJpJGkkYAAAAAgDGSRgAAAAAwQNJI0ggAAAAAyANJIwAAAAAYIWgkaQQAAAAAGCNpBAAAAAAD7GmkaQQAAAAAQzSNLE8FAAAAAOSBpBEAAAAADJA0kjQCAAAAAPJA0ggAAAAABkgaSRoBAAAAAHkgaQQAAAAAIwSNJI0AAAAAAGMkjQAAAABggD2NJI0AAAAAgDyQNAIAAACAAZJGmkYAAAAAMETTyPJUAAAAAEAeSBoBAAAAwABJI0kjAAAAACAPJI0AAAAAYISgkaQRAAAAAGCMpBEAAAAADLCnkaQRAAAAAJAHkkYAAAAAMEDSSNMIAAAAAIZoGlmeCgAAAADIA0kjAAAAABghaCRpBAAAAAAYI2kEAAAAAAPsaSRpBAAAAADkgaQRAAAAAAyQNJI0AgAAAADyQNIIAAAAAAZIGmkaAQAAAMAQTSPLUwEAAAAAeSBpBAAAAAAjBI0kjQAAAAAAYzSNAAAAAGDAZDK57CgMq9WqHj16KDo62j6WmJioUaNGyWKx6KGHHtLmzZsdPvPZZ5+pc+fOslgsGjdunC5cuFCge9I0AgAAAEAxkJGRoYkTJyouLs4+lpmZqeDgYHl6euqjjz7SiBEjNHnyZP3888+SpIMHD2r69OkKCQlRVFSULl26pNDQ0ALdlz2NAAAAAGCgqDw9NT4+XpMmTZLNZnMY37Fjh5KSkvT+++/Lx8dHd911l3bu3Kn9+/erYcOGWr16tbp3766ePXtKkl599VV16NBBCQkJql27dr7uTdIIAAAAAEXcnj17FBAQoKioqBzjbdq0kY+Pj33sjTfe0D//+U9JUmxsrFq1amU/V716ddWoUUOxsbH5vjdJIwAAAAAYcGXSaLVaZbVaHcbMZrPMZnOOawcOHJjrHAkJCapZs6bmz5+vTz75RBUrVtSECRPUuXNnSdKvv/6qqlWrOnzG19dX586dy3edJI0AAAAAYMTkuiMiIkItW7Z0OCIiIgpU3tWrV/XRRx/p0qVLWrZsmXr27KkJEybo0KFDkqRr167laELNZnOOZjUvJI0AAAAA4AbBwcEaNmyYw1huKWNeSpQooQoVKmjWrFny8PCQn5+f9u7dqw8//FDNmjWTl5dXjgbRarWqVKlS+b4HTSMAAAAAGHDl8lSjpagFUbVqVZlMJnl4/N8i0nr16umnn36SJFWrVk0pKSkOn0lJSVGVKlXyfQ+WpwIAAABAMWWxWBQXF6esrCz72PHjx1WzZk37+ZiYGPu5pKQkJSUlyWKx5PseNI0AAAAAYMBkMrnscIYePXooOztbL774ok6fPq01a9bom2++Ub9+/SRJAwYM0CeffKK1a9fq2LFjmjx5sgIDA/P9ug2J5alAkffF9m2a+HSIw1jnh7rq4sXftfeHPTmuf6xXb81+ae6tKg8AkE8pv57T8kVzdeTgfvmULacejw9Ujz6OT0M8emi/Fr8yU2+u+dRNVQIobnx8fPT2229r1qxZ6tGjh2rUqKHXX39dfn5+kiR/f3/Nnj1bixcvVmpqqtq2bauwsLAC3YOmESjiThyP14OBHTRj1v/9l9vs5SVbdrauX79uHzt0KFb/mviM/tk/98cxAwDca8HsqapSrbpeXbZaZ0+f0KI501Wl2h0KaN9RknT6RJzmz5qikn9xfxMA53LlnsbC+nO/4p/uvvturV692vD63r17q3fv3oW+H00jUMSdOHFcdzdoqMp5bFbOysrS4kWva+jwkfJr2uwWVgcAyI+0y5f085FDGjPpedWodadq1LpTLVrfr4P7flBA+47aunG93lm2SNWq19TVK2nuLhcAHLCnESjiThw/rjp16uZ5zScfb9Cl1FQNHzHq1hQFACgQs5eXvLy99eWWT5WZeV2/nDmlnw7Hql6DRpKkfXu+0/gpL+ZYrgrA/Yr6nsZboUgkjb///rv9XSHlypVzdzlAkWGz2XTq1Ent+u5brXgrQtnZWXqoSzeNC5lgX75ks9n0duQKDRr8pEqXKePmigEAuTGbvTRywhRFLn5Vm9Z/oOzsLHXo+og6B/WUJE0NWyhJ+nILexmBIqf49HYu47amcevWrVq9erUOHjyojIwM+7i3t7eaNm2qIUOGqHPnzu4qDygSkpISdS09XWazWa8tWKRffjmreXNfUkbGNU0JfV6S9MOeaP16/pwe79PPzdUCAPLyy5lTatnmAT3a7wmdORmvyCWvqXnL+/RA5yB3lwYAeXJL0/j2228rPDxcI0eOVEhIiHx9fWU2m2W1WpWSkqK9e/dq6tSpevrppzV48GB3lAgUCTVq1NTO76JVrnx5mUwm3dO4sWzZ2Zo29V96bnKoSpQooe1b/6u27R5Q+QoV3F0uAMDAwX17tH3zx1oetVleXt66u1ETXUhJ1rrVkTSNQBFXnJaRuopbmsaVK1dq3rx5uSaJ9evXV0BAgBo1aqSwsDCaRvzt3dgM1rurvjIyMpSamqpKlSrpu+++0VNjQ3L/MACgSDjx81FVr1lbXl7e9rF6dzfS+jWRbqwKAPLHLQ/CuXbtmmrVqpXnNdWqVdPly5dvUUVA0fTdt9/ogfsDlJ6ebh/76dhRVahQQZUqVdLvv1/Q2YQE+fu3dGOVAICbqehbRed+SXB4VdIvCadU9Y6abqwKQH7wIBw3NY0PPfSQpk6dqr179yozM9PhXHZ2tvbt26dp06apa9eu7igPKDJa+PvLy9tLL854XqdOntC33+zQwgWvaujwkZKk+Lg4eXl5qeZN/hIGAOBerdq0VwlPT705P0yJCaf1w66d2rBmpR7u3d/dpQHATblleeqsWbM0b948jRgxQllZWapQoYJ9T+PFixfl6empxx57TKGhoe4oDygyypTx0ZvLI/XaKy9rQL/HVaZMGfXp19/eNP72228qW7ZcsfqbKgD4OyrjU1az5i/TyqXzNWXsYJUrX1F9nhiph3oU/mXbAG4N/m+WZLLZbDZ33Tw9PV3Hjh1TcnKy0tPT5eXlpWrVqqlx48by9va++QQGrmXe/BoAQNEXf56XnAPA7aBpTR93l1Bodz/3ucvmjp/f3WVzO5Nb39NYqlQp+fv7u7MEAAAAADDEii43N40AAAAAUJTRM7rpQTgAAAAAgOKBpBEAAAAADLA8laQRAAAAAJAHkkYAAAAAMEDQSNIIAAAAAMgDSSMAAAAAGPDwIGokaQQAAAAAGCJpBAAAAAAD7GmkaQQAAAAAQ7xyg+WpAAAAAIA8kDQCAAAAgAGCRpJGAAAAAEAeSBoBAAAAwAB7GkkaAQAAAAB5IGkEAAAAAAMkjSSNAAAAAIA8kDQCAAAAgAGCRppGAAAAADDE8lSWpwIAAAAA8kDSCAAAAAAGCBpJGgEAAAAAeSBpBAAAAAAD7GkkaQQAAAAA5IGkEQAAAAAMEDSSNAIAAAAA8kDSCAAAAAAG2NNI0ggAAAAAyANJIwAAAAAYIGikaQQAAAAAQyxPZXkqAAAAACAPJI0AAAAAYICgkaQRAAAAAJAHkkYAAAAAMMCeRpJGAAAAAEAeSBoBAAAAwABBI0kjAAAAACAPJI0AAAAAYIA9jTSNAAAAAGCInpHlqQAAAACAPJA0AgAAAIABlqeSNAIAAAAA8kDSCAAAAAAGSBpJGgEAAAAAeSBpBAAAAAADBI0kjQAAAACAPJA0AgAAAIAB9jSSNAIAAACAIZPJdUdhWK1W9ejRQ9HR0TnOXb58We3bt9eGDRscxj/77DN17txZFotF48aN04ULFwp0T5pGAAAAACgGMjIyNHHiRMXFxeV6/rXXXtOvv/7qMHbw4EFNnz5dISEhioqK0qVLlxQaGlqg+7I8FQAAAAAMFJXlqfHx8Zo0aZJsNluu5/fu3avvv/9eVapUcRhfvXq1unfvrp49e0qSXn31VXXo0EEJCQmqXbt2vu5N0ggAAAAAbmC1WpWWluZwWK3WXK/ds2ePAgICFBUVles8L7zwgmbMmCGz2exwLjY2Vq1atbL/XL16ddWoUUOxsbH5rpOkEQAAAAAMuDJojIiIUHh4uMNYSEiIxo8fn+PagQMHGs6zbNkyNWnSRO3atctx7tdff1XVqlUdxnx9fXXu3Ll810nTCAAAAABuEBwcrGHDhjmM3ZgU3kx8fLw++OADffrpp7mev3btWo45zWazYaKZG5pGAAAAADDg4cKo0Ww2F7hJ/F82m03PP/+8JkyYoMqVK+d6jZeXV44G0Wq1qlSpUvm+D00jAAAAABRDiYmJ2r9/v3766SfNmzdPkpSenq6ZM2dq8+bNWrFihapVq6aUlBSHz6WkpOR4YE5eaBoBAAAAwEAReXhqrqpVq6atW7c6jA0ePFiDBw/Wo48+KkmyWCyKiYlR7969JUlJSUlKSkqSxWLJ931oGgEAAADAQFF55UZuPD09VadOnRxjvr6+qlatmiRpwIABGjx4sFq0aKFmzZppzpw5CgwMzPfrNiSaRgAAAAC4bfn7+2v27NlavHixUlNT1bZtW4WFhRVoDpPN6O2Qxdi1THdXAABwhvjzae4uAQDgBE1r+ri7hELr/ma0y+b+fEyAy+Z2Jg93FwAAAAAAKLpYngoAAAAABorynsZbhaQRAAAAAGCIpBEAAAAADBA0kjQCAAAAAPJA0ggAAAAABkwiaqRpBAAAAAADHvSMLE8FAAAAABgjaQQAAAAAA7xyo5BJ46VLl5SRkSFJOnbsmFasWKHdu3c7tTAAAAAAgPsVuGncvn27HnjgAcXExOj06dMaNGiQPvroI40dO1arV692RY0AAAAA4BYmk+uO4qLATeOiRYs0YcIE3X///Vq7dq2qV6+uTZs2aeHChVq5cqUragQAAAAAuEmB9zSeOXNG3bt3lyR98cUX6tatmySpQYMGunDhgnOrAwAAAAA38ihOkaCLFLhprFGjhqKjo1WtWjWdPHlSHTt2lCRt3LhRdevWdXZ9AAAAAAA3KnDTOGHCBE2ePFlZWVkKDAxUs2bNNG/ePH3wwQcKDw93RY0AAAAA4BYEjZLJZrPZCvqhCxcu6Pz582rcuLEk6cSJEypXrpwqV67s9AIL41qmuysAADhD/Pk0d5cAAHCCpjV93F1CofV5e5/L5l437F6Xze1MhXrlRvny5XX+/HmtWrVKly5d0uXLl+Xl5eXs2gAAAAAAblbg5alJSUkaPny4UlNTlZqaqk6dOmnFihXav3+/IiMj1ahRI1fUCQAAAAC3HMtTC5E0zp49W61atdI333wjs9ksSVq4cKHuv/9+vfTSS04vEAAAAADgPgVOGvfu3asPP/xQJUqUsI+VLFlSY8eOVa9evZxaHAAAAAC4E6/cKETS6O3trd9++y3H+MmTJ+XjU3w3uAIAAAAAcipw09i/f3/NmDFDX3/9taQ/msX169frhRdeUJ8+fZxdHwAAAAC4jcmFR3FR4OWp48aNU7ly5TRr1iylp6dr9OjR8vX11dChQzVixAhX1AgAAAAAcJMCN42SNHjwYA0ePFhXr15VVlaWypYt6+y6AAAAAMDtTOxpLHjT+PHHH+d5vmfPnoUsBQAAAACKFg96xoI3jYsXL3b4OSsrS7/99ps8PT3VvHlzmkYAAAAAuI0UuGn88ssvc4xduXJFM2bMUKNGjZxSFAAAAAAUBSxPLcTTU3NTpkwZjR8/Xm+//bYzpgMAAAAAFBGFehBObo4dO6bs7GxnTQcAAAAAbkfQWIimcfDgwTki2itXruinn37S0KFDnVUXAAAAAKAIKHDTGBAQkGPMbDbrueeeU5s2bZxSFAAAAAAUBexpLETTGBIS4oo6AAAAAABFUL6axtDQ0HxPOHfu3EIXAwAAAABFCe9pdOKDcAAAAADgdsPy1Hw2jaSHAAAAAPD3VOCk0Waz6YsvvlBcXJyysrLs41arVUeOHNGKFSucWiAAAAAAuAs5YyGaxrCwMK1bt05NmjTRwYMH5e/vrzNnziglJUUDBgxwRY0AAAAAADfxKOgHNm/erPnz5+uDDz7QnXfeqVmzZumrr77Sww8/rOvXr7uiRgAAAABwCw+TyWVHcVHgpjEtLU1NmzaVJDVs2FAHDx6Up6engoODtWPHDqcXCAAAAABwnwI3jbVr19aRI0ckSQ0aNNDBgwcl/bHX8fLly86tDgAAAADcyGRy3VFcFHhP4/Dhw/Xcc8/p5ZdfVlBQkHr37i1PT0/t379fLVu2dEWNAAAAAAA3yVfSGBkZqfPnz0uS+vbtq7feekt16tRR/fr1FR4eruTkZDVt2pRXcwAAAAC4rZhMJpcdxYXJZrPZbnZR165dlZCQoJYtW+qRRx5R165dVb58+VtRX6Fcy3R3BQAAZ4g/n+buEgAATtC0po+7Syi00Wt/dNncy/v6uWxuZ8pX0vjf//5X69atk7+/v1asWKF27dppzJgx2rx5szIyMlxdIwAAAAC4BXsa85k03ujw4cPasmWLtmzZogsXLqhTp07q0aOH2rVrpxIlSriizgIhaQSA2wNJIwDcHopz0jhm/RGXzf3m401cNrczFapp/F+HDh3S9u3btW3bNl28eFG7du1yVm2FRtMIALcHmkYAuD3QNOauuDSNBX566v+6cOGCjh07pmPHjikpKUn33HOPs+oCAAAAALcrTstIXaXATeP58+e1detWbd26Vfv27VODBg0UFBSkmTNnqkaNGq6oEQAAAADgJvlqGs+cOWNvFA8fPqyaNWvq4Ycf1syZM3X33Xe7ukYAAAAAcIvi9GoMV8lX09ilSxdVqVJF3bp10/PPP6/mzZu7ui4AAAAAQBGQr6bx7bffVkBAgDw88vWGDrfb/GOSu0sAADjBoKFz3F0CAMAJ0veHu7uEQiseHZBr5atpbNOmjavrAAAAAAAUQX/p6akAAAAAcDtjTyNNIwAAAAAY8qBnZIkuAAAAAMBYvpLG0NDQfE84d+7cQhcDAAAAAEUJSSNJIwAAAAAgD/lKGkkPAQAAAPwdFbUH4VitVvXu3VsvvPCCAgICJEkHDhzQK6+8op9++klVq1bVyJEj1bdvX/tndu3apZdfflkJCQmyWCyaM2eOateune97FvhBODabTV988YXi4uKUlZXlUPyRI0e0YsWKgk4JAAAAALiJjIwMTZo0SXFxcfax5ORkjRo1SgMGDNArr7yiH3/8UaGhoapSpYoCAwOVmJiocePGafz48Wrfvr2WLl2qsWPH6tNPP813Q1zgpjEsLEzr1q1TkyZNdPDgQfn7++vMmTNKSUnRgAEDCjodAAAAABRZRWVPY3x8vCZNmiSbzeYwvn37dlWuXFkTJ06UJNWtW1fR0dHauHGjAgMDtXbtWjVt2lTDhw+X9Mcq0rZt22rPnj32pPJmCryncfPmzZo/f74++OAD3XnnnZo1a5a++uorPfzww7p+/XpBpwMAAAAA3MSfTV5UVJTDePv27XPdTpiWliZJio2NVatWrezjpUqVkp+fnw4cOJDvexc4aUxLS1PTpk0lSQ0bNtTBgwfVoEEDBQcHa8SIEQWdDgAAAACKLFduabRarbJarQ5jZrNZZrM5x7UDBw7MdY5atWqpVq1a9p9/++03bdq0SePHj5f0x/LVqlWrOnzG19dX586dy3edBU4aa9eurSNHjkiSGjRooIMHD0r6Y6/j5cuXCzodAAAAABRZHiaTy46IiAi1bNnS4YiIiCh0rdeuXdP48eNVuXJl/fOf/5Qkpaen52hCzWZzjmY1LwVOGocPH65//etfmjNnjoKCgtS7d295enpq//79atmyZUGnAwAAAIC/peDgYA0bNsxhLLeUMT+uXLmisWPH6tSpU/rPf/6jUqVKSZK8vLxyNIhWq1XlypXL99wFbhr79u2runXrqnTp0qpfv77Cw8Ptmyv/jEABAAAA4HbgyhfbGy1FLai0tDSNHDlSZ86c0TvvvKO6devaz1WrVk0pKSkO16ekpKhx48b5nr/ATaMktW7d2v7n9u3bq3379oWZBgAAAADwF2RnZyskJERnz57Ve++9p/r16zuct1gsiomJsf+cnp6uI0eOKCQkJN/3KHDTOHjw4Dzf5/Huu+8WdEoAAAAAKJJc+SAcZ1i3bp2io6P15ptvqly5ckpOTpYklSxZUhUqVNDjjz+uyMhILV++XB06dNDSpUtVq1atfL9uQypE03jj5JmZmUpISNCOHTs0ZsyYgk4HAAAAACik//73v8rOzlZwcLDD+H333af33ntPtWrV0pIlS/Tyyy9r6dKl8vf319KlS/MMAm9kst34dshC2rBhg7Zu3aply5Y5Y7q/VktskrtLAAA4waChc9xdAgDACdL3h7u7hEJ7YUucy+YO69bAZXM7k9P2dbZu3Vq7d+921nQAAAAAgCKgwMtTExMTc4xduXJFkZGRqlmzplOKAgAAAICioKjvabwVCtw0duzYMcf6V5vNpurVq2vOHJYRAQAAALh9eNA0Frxp/OKLLxx+NplMKlmypCpXrlygzZQAAAAAgKKvwHsaQ0NDVbZsWdWsWVM1a9ZUjRo1VKVKFf3+++/q3bu3K2oEAAAAALfwMJlcdhQX+Uoad+7cqYMHD0qSfvjhBy1btkylS5d2uOb06dP65ZdfnF8hAAAAAMBt8tU01qtXTytWrJDNZpPNZtO+fftUsmRJ+3mTyaTSpUuzpxEAAADAbaUYBYIuk6+msXbt2nr33Xcl/bE8dfr06fLx8XFpYQAAAAAA9yvwnsYXX3xRb7zxhtasWWMf6927t+bPn6/r1687tTgAAAAAcCcPk+uO4qLATeNLL72kHTt26J577rGPjR07Vl9//bXmzZvn1OIAAAAAAO5V4KZx69atmj9/vlq2bGkf69y5s+bOnavNmzc7tTgAAAAAcCeTC/8pLgr8nkabzaaMjIxcx1meCgAAAOB2UpyWkbpKgZPGrl276oUXXtDevXt19epVXb16Vfv27dOsWbPUuXNnV9QIAAAAAHCTAieNfz49dciQIcrOzpbNZpOnp6d69uypcePGuaJGAAAAAHALksZCNI2lSpXSwoULdenSJZ0+fVpZWVk6deqUNm7cqM6dO+vHH390RZ0AAAAAADcocNP4p7i4OH388cfasmWL0tLSVL9+fU2bNs2ZtQEAAACAW5lMRI0Fahp/+eUXffzxx/rkk0+UkJCgcuXKKS0tTQsWLFBQUJCragQAAAAAuEm+msb169fr448/1t69e1W1alV17NhRXbp0UevWrWWxWNSwYUNX1wkAAAAAtxx7GvPZNE6fPl116tTRvHnz9Oijj7q6JgAAAABAEZGvV268/PLLqlWrlkJDQ9WmTRuFhobqiy++yPV9jQAAAABwuzCZXHcUF/lKGnv37q3evXvrwoUL+vzzz7V582aFhITI29tb2dnZio6OVp06dVSyZElX1wsAAAAAt4xHceruXCRfSeOfKlWqpEGDBmnNmjX66quvNG7cODVu3FhhYWFq37695s6d66o6AQAAAABuUKCm8X/dcccdGjlypDZs2KAtW7boiSee0DfffOPM2gAAAADArTxMrjuKi0I3jf+rbt26CgkJ0ebNm50xHQAAAACgiCjQexoBAAAA4O+ELY1OShoBAAAAALcnkkYAAAAAMOAhokaSRgAAAACAIZJGAAAAADDAnkaaRgAAAAAwVJxejeEqLE8FAAAAABgiaQQAAAAAAx6sTyVpBAAAAAAYI2kEAAAAAAMEjSSNAAAAAIA8kDQCAAAAgAH2NJI0AgAAAADyQNIIAAAAAAYIGmkaAQAAAMAQSzP5HQAAAAAA8kDSCAAAAAAGTKxPJWkEAAAAABgjaQQAAAAAA+SMJI0AAAAAgDyQNAIAAACAAQ/2NJI0AgAAAACMkTQCAAAAgAFyRppGAAAAADDE6lSWpwIAAAAA8kDSCAAAAAAGTESNJI0AAAAAAGMkjQAAAABggJSN3wEAAAAAIA8kjQAAAABggD2NJI0AAAAAgDyQNAIAAACAAXJGkkYAAAAAQB5oGgEAAADAgMlkctlRGFarVT169FB0dLR9LCEhQUOHDlWLFi0UFBSkb7/91uEzu3btUo8ePWSxWPTkk08qISGhQPekaQQAAAAAAx4uPAoqIyNDEydOVFxcnH3MZrNp3Lhxqly5stavX6/HHntMISEhSkxMlCQlJiZq3Lhx6t27t9atW6dKlSpp7NixstlsBfodAAAAAACKsPj4ePXr109nzpxxGP/++++VkJCg2bNnq379+goODlaLFi20fv16SdLatWvVtGlTDR8+XA0aNNDcuXP1yy+/aM+ePfm+N00jAAAAABgoKstT9+zZo4CAAEVFRTmMx8bGqkmTJipdurR9rGXLljpw4ID9fKtWreznSpUqJT8/P/v5/ODpqQAAAADgBlarVVar1WHMbDbLbDbnuHbgwIG5zpGcnKyqVas6jPn6+urcuXP5Op8fJI0AAAAAYMDkwiMiIkItW7Z0OCIiIgpUX3p6eo4m02w225vRm53PD5JGAAAAAHCD4OBgDRs2zGEst5QxL15eXrp48aLDmNVqlbe3t/38jQ2i1WpVuXLl8n0PmkYAAAAAMFDIN2Pki9FS1IKoVq2a4uPjHcZSUlLsS1KrVaumlJSUHOcbN26c73uwPBUAAAAAiimLxaIff/xR165ds4/FxMTIYrHYz8fExNjPpaen68iRI/bz+UHTCAAAAAAGPGRy2eEM9913n6pXr67Q0FDFxcVp+fLlOnjwoPr06SNJevzxx7Vv3z4tX75ccXFxCg0NVa1atRQQEFCA3wEAAAAAIFcmk+sOZyhRooTeeOMNJScnq3fv3vr000+1dOlS1ahRQ5JUq1YtLVmyROvXr1efPn108eJFLV26tECv/GBPIwAAAAAUIz/99JPDz3Xq1NHq1asNr3/wwQf14IMPFvp+NI0AAAAAYMDkpGWkxRnLUwEAAAAAhkgaAQAAAMCAK1+5UVyQNAIAAAAADJE0AgAAAIABZ70aozgjaQQAAAAAGCJpBAAAAAAD7GmkaQQAAAAAQzSNLE8FAAAAAOSBpBEAAAAADJh4EA5JIwAAAADAGEkjAAAAABjwIGgkaQQAAAAAGCNpBAAAAAAD7GkkaQQAAAAA5IGkEQAAAAAM8J5GmkYAAAAAMMTyVJanAgAAAADyQNIIAAAAAAZ45QZJIwAAAAAgDySNAAAAAGCAPY0kjUCRlXndqkWThurEj/vtYxd+TdKKsImaMbibXn92iH6O/SHXz+7/ZpuWz3r6VpUKAMiDuaSn9q6dpvYtG9jH/BvX1tfvTFLydwu0451Juq9ZXYfPdAhopL1rp+m3XQv1ecR41a3pe4urBoD/Q9MIFEHXrRn64N9hOp9wyj5ms9n03mvPq2z5SgqZGyH/B7po9fwXdDHlvMNnjx/er4+WL7jFFQMAcuNl9tS7c4fK7+4a9rEqFX20OWK8Dsclqu2gV7Vu6z599maIat9RUZJU+46K+nDhaL336fdq98SrSvk9TR8uHO2urwD87ZlMrjuKC5pGoIg5f/aU3pw+Vr+dT3QYP/Hjfl0494t6jZ6kqrXqKLDXIN3ZsIn2frnZfs32tau0au5kVapa/VaXDQC4wT133aEd7z6nerUrO4wP6hGgCxevaMLLH+jnU+e1ZM1X2nXguEb1bS9JGtrrfu07ckb/fu9LHT1xTqNnrVadGpUckkoAuJVoGoEi5uSRWN3l568xLy11GD/z8xHVuKuhzN6l7GN1GzXTmbgj9p/jD+7VsOmvqWnAA7esXgBA7tq3vFs7f/hZgUMcV3/UreWr/UcTlJ1ts48d/jlRAc3rSZLua1ZX3+6Lt59Lv3ZdB46dVYCl3q0pHIADkwuP4oIH4QBFzD+6PJbr+OWLv6lcRcc9LT4VKin1t2T7z0+FhUuSThzeLwCAe7219ttcx3/97bKaN6zpMFbrjoryrVBGknRH5fJKSk694TOXVLNqBZfUCSBvHsVpHamLkDQCxcT1jAyV8DQ7jHl6llTmdaubKgIAFMbHXxxQ66Z1NazX/SpRwkOd2zRWj8BmMpf84+/yS3uXVIY10+EzGdcz5WXm7/oBuAdNI1BMeJY0KyvTsUHMzLwus5e3myoCABTGkeNJGhv2vuZN6q3U6EV6MeQRLf/wG126ck2SdM2as0H0Kump9Gv8JSHgDixPdePy1B9+yP1VAblp3bq1CysBiodylSrr/NmTDmOXL15Q2Yo8hh0Aipv3Pv1eaz6LVtVKZXUu5ZLmPP2YziT+JklK/PWiqvmWc7i+WuVyiv35F3eUCgDuaxpnz56t+Pg/NnnbbDbD60wmk44ePXqrygKKrDsbNtGOT/6j69YMlTR7SZJOHzukOvc0c3NlAICCeKBVA43s005PTn1b51IuSZK6tPXTinV/7IHcc+iU7ve/y359Ke+SsjSqpZeWbc51PgAuVpwiQRdxW9O4fv16TZw4UWfPnlVUVJS8vLzcVQpQLNRrYlF536pa98Yr6vj4kzoas0sJ8UfVZ+wUd5cGACiA+NO/KuiBphrVt5227TqqZ57spIrlSmn1xu8lSe98vFvPPtlJzw17SJt2HNK00d11KvE37dwb5+bKAfxduW1Po9ls1sKFCyVJixYtclcZQLHh4VFCgye/pMu/X1D41NE68M02DX4uTBUqV3N3aQCAAkhMTtUTk1dqbP9A7V07TQ3rVFPQU+G6kv7HnsUzSRfU/7kVGvzoP/Tt6smqVKGM+j37lpurBv6+TC78p7gw2fJaG3oLHD9+XHv27NGAAQOcNueG2CSnzQUAcJ9BQ+e4uwQAgBOk7w93dwmFFn089eYXFVJA/fIum9uZ3P7s5vr166t+/fruLgMAAAAAcuA1jUWgaQQAAACAooqekfc0AgAAAADyQNIIAAAAAEaIGkkaAQAAAADGSBoBAAAAwEBxejWGq5A0AgAAAAAMkTQCAAAAgAFeuUHSCAAAAADIA0kjAAAAABggaKRpBAAAAABjdI0sTwUAAAAAGCNpBAAAAAADvHKDpBEAAAAAkAeSRgAAAAAwwCs3SBoBAAAAAHkgaQQAAAAAAwSNJI0AAAAAgDyQNAIAAACAEaJGmkYAAAAAMMIrN1ieCgAAAADIA0kjAAAAABjglRskjQAAAACAPJA0AgAAAIABgkaSRgAAAABAHmgaAQAAAMCIyYVHASQlJSk4OFj33nuvOnbsqFWrVtnPHTlyRH379pXFYtHjjz+uw4cPF/bb5oqmEQAAAACKuGeeeUalS5fWhg0bNG3aNC1atEjbtm3T1atXNXr0aLVq1UobNmyQv7+/goODdfXqVafdm6YRAAAAAAyYXPhPfqWmpurAgQMaM2aM6tatq86dO6t9+/bavXu3Nm/eLC8vL02ePFn169fX9OnTVaZMGW3ZssVpvwOaRgAAAAAowry9vVWqVClt2LBB169f14kTJ7Rv3z41btxYsbGxatmypUz//90gJpNJ9957rw4cOOC0+9M0AgAAAIABk8l1h9VqVVpamsNhtVpz1ODl5aUZM2YoKipKFotF3bt31wMPPKC+ffsqOTlZVatWdbje19dX586dc9rvgFduAAAAAIABV75yIyIiQuHh4Q5jISEhGj9+fI5rjx8/rg4dOmjYsGGKi4tTWFiY2rRpo/T0dJnNZodrzWZzrs1nYdE0AgAAAIAbBAcHa9iwYQ5jNzaAkrR7926tW7dOO3bskLe3t5o1a6bz58/rzTffVO3atXM0iFarVd7e3k6rk+WpAAAAAGDEha/cMJvN8vHxcThyaxoPHz6sOnXqODSCTZo0UWJioqpVq6aUlBSH61NSUnIsWf0raBoBAAAAoAirWrWqTp8+7ZAonjhxQrVq1ZLFYtH+/ftls9kkSTabTfv27ZPFYnHa/WkaAQAAAMBAUXjlRseOHVWyZEk9//zzOnnypL788kstW7ZMgwcPVrdu3XTp0iXNmTNH8fHxmjNnjtLT09W9e3en/Q5oGgEAAACgCCtbtqxWrVql5ORk9enTR3PnztWYMWP0z3/+Uz4+PoqIiFBMTIx69+6t2NhYLV++XKVLl3ba/U22P3PM28iG2CR3lwAAcIJBQ+e4uwQAgBOk7w+/+UVF1E/nrrps7kZ3OK+xcyWSRgAAAACAIV65AQAAAAAGXPmexuKCphEAAAAAjNA1sjwVAAAAAGCMpBEAAAAADBTk1Ri3K5JGAAAAAIAhkkYAAAAAMGAiaCRpBAAAAAAYI2kEAAAAAAMEjSSNAAAAAIA8kDQCAAAAgBGiRppGAAAAADDCKzdYngoAAAAAyANJIwAAAAAY4JUbJI0AAAAAgDyQNAIAAACAAYJGkkYAAAAAQB5IGgEAAADACFEjSSMAAAAAwBhJIwAAAAAY4D2NNI0AAAAAYIhXbrA8FQAAAACQB5JGAAAAADBA0EjSCAAAAADIA0kjAAAAABhgTyNJIwAAAAAgDySNAAAAAGCIqJGkEQAAAABgiKQRAAAAAAywp5GmEQAAAAAM0TOyPBUAAAAAkAeSRgAAAAAwwPJUkkYAAAAAQB5IGgEAAADAgIldjSSNAAAAAABjJI0AAAAAYISgkaQRAAAAAGCMpBEAAAAADBA00jQCAAAAgCFeucHyVAAAAABAHkgaAQAAAMAAr9wgaQQAAAAA5IGkEQAAAACMEDSSNAIAAAAAjJE0AgAAAIABgkaSRgAAAABAHkgaAQAAAMAA72mkaQQAAAAAQ7xyg+WpAAAAAIA8kDQCAAAAgAGWp5I0AgAAAADyQNMIAAAAADBE0wgAAAAAMMSeRgAAAAAwwJ5GkkYAAAAAQB5IGgEAAADAAO9ppGkEAAAAAEMsT2V5KgAAAAAUeVarVS+++KJat26t+++/XwsXLpTNZpMkHTlyRH379pXFYtHjjz+uw4cPO/XeNI0AAAAAYMDkwqMgXnrpJe3atUuRkZFasGCBPvzwQ0VFRenq1asaPXq0WrVqpQ0bNsjf31/BwcG6evXqX/zm/4flqQAAAABQhF28eFHr16/X22+/rebNm0uShg8frtjYWHl6esrLy0uTJ0+WyWTS9OnTtXPnTm3ZskW9e/d2yv1JGgEAAADASBGIGmNiYuTj46P77rvPPjZ69GjNnTtXsbGxatmypUz/f/OlyWTSvffeqwMHDhT6K9+IphEAAAAA3MBqtSotLc3hsFqtOa5LSEhQzZo19fHHH6tbt27q1KmTli5dquzsbCUnJ6tq1aoO1/v6+urcuXNOq5PlqQAAAABgwJWv3IiIiFB4eLjDWEhIiMaPH+8wdvXqVZ0+fVoffPCB5s6dq+TkZM2YMUOlSpVSenq6zGazw/VmsznX5rOwaBoBAAAAwA2Cg4M1bNgwh7EbG0BJ8vT0VFpamhYsWKCaNWtKkhITE/X++++rTp06ORpEq9Uqb29vp9VJ0wgAAAAABlz5nkaz2Zxrk3ijKlWqyMvLy94wSlK9evWUlJSk++67TykpKQ7Xp6Sk5Fiy+lewpxEAAAAAijCLxaKMjAydPHnSPnbixAnVrFlTFotF+/fvt7+z0Wazad++fbJYLE67P00jAAAAABgoAg9P1V133aXAwECFhobq2LFj+uabb7R8+XINGDBA3bp106VLlzRnzhzFx8drzpw5Sk9PV/fu3Z3w7f9A0wgAAAAARopC1yhp/vz5uvPOOzVgwABNmTJFgwYN0uDBg+Xj46OIiAjFxMSod+/eio2N1fLly1W6dOm/+s3tTLY/c8zbyIbYJHeXAABwgkFD57i7BACAE6TvD7/5RUXU1euua5dKl3Thhkkn4kE4AAAAAGDAla/cKC5YngoAAAAAMETSCAAAAAAGXPnKjeKCpBEAAAAAYOi2fBAOAAAAAMA5SBoBAAAAAIZoGgEAAAAAhmgaAQAAAACGaBoBAAAAAIZoGgEAAAAAhmgaAQAAAACGaBoBAAAAAIZoGgEAAAAAhmgaAQAAAACGaBqBYiYjI0PTpk1Tq1at1K5dO61cudLdJQEA/gKr1aoePXooOjra3aUAQK483V0AgIJ59dVXdfjwYb3zzjtKTEzUlClTVKNGDXXr1s3dpQEACigjI0OTJk1SXFycu0sBAEM0jUAxcvXqVa1du1ZvvfWW/Pz85Ofnp7i4OK1Zs4amEQCKmfj4eE2aNEk2m83dpQBAnlieChQjx44dU2Zmpvz9/e1jLVu2VGxsrLKzs91YGQCgoPbs2aOAgABFRUW5uxQAyBNJI1CMJCcnq2LFijKbzfaxypUrKyMjQxcvXlSlSpXcWB0AoCAGDhzo7hIAIF9IGoFiJD093aFhlGT/2Wq1uqMkAAAA3OZoGoFixMvLK0dz+OfP3t7e7igJAAAAtzmaRqAYqVatmn7//XdlZmbax5KTk+Xt7a1y5cq5sTIAAADcrmgagWKkcePG8vT01IEDB+xjMTExatasmTw8+K8zAAAAnI//lwkUI6VKlVLPnj01a9YsHTx4UNu3b9fKlSv15JNPurs0AAAA3KZ4eipQzISGhmrWrFkaMmSIfHx8NH78eHXp0sXdZQEAAOA2ZbLxRlkAAAAAgAGWpwIAAAAADNE0AgAAAAAM0TQCAAAAAAzRNAIAAAAADNE0AgAAAAAM0TQCAAAAAAzRNAIAAAAADNE0AgAAAAAM0TQCwG2mY8eOatSokf3w8/NTt27dtGrVKqfeZ/DgwVqyZIkkaerUqZo6depNP2O1WvXhhx8W+p4bNmxQx44dc4ynpaXJYrEYzv38889r1KhRhZobAIC/O093FwAAcL5p06YpKChIkpSZmanvv/9e06dPV4UKFdSzZ0+n32/69On5um7Tpk1atmyZ+vXr59T7+/j4KDAwUFu3bs0xd2ZmprZt26Zp06Y59Z4AAPxdkDQCwG2obNmyqlKliqpUqaLq1aurV69eatOmjbZu3eqy+5UtW/am19lsNpfcX5J69Oih77//XpcvX3YY3717tzIyMtS5c2eX3RsAgNsZTSMA/E14enqqZMmSkv5YWhoWFqZOnTopMDBQaWlpSkpK0lNPPSWLxaKOHTsqPDxcWVlZ9s9v27ZNXbt2VYsWLTR79myHczcuT/3kk0/UrVs3WSwW9e/fX0eOHFF0dLRCQ0P1yy+/qFGjRjp79qxsNpuWLl2qdu3aqVWrVnrqqaeUmJhon+f8+fMaOXKkWrRooV69eunMmTOG3+/BBx+Ut7e3vvzyS4fxzz//XB06dFCZMmUUExOjAQMGyGKxqEWLFho1apR+/fXXHHNFR0erUaNGDmM3fsdt27YpKChIFotFffr00Z49e+znjh07pv79+8tisah9+/YKDw83rBsAgKKOphEAbnPXr1/X1q1b9d1336lTp0728Q0bNui1115TeHi4ypQpo5CQEPn6+uqjjz7S3LlztXHjRi1btkySFB8fr2eeeUYDBgzQ+vXrlZmZqZiYmFzv980332j69OkaMmSIPv30UzVt2lTBwcHy9/fXtGnTdMcdd+jbb79V9erVtXr1am3cuFELFixQVFSUfH19NXz4cF2/fl2S9PTTTys7O1tr167VqFGj9M477xh+T7PZrIceesghTb1+/bq++OIL9ejRQ5cvX1ZwcLDatm2rzz77TJGRkTpz5oyWL19e4N/psWPHNGXKFI0ZM0affvqpHn30UY0aNUqnT5+WJE2ePFmNGzfWZ599pjlz5mjFihXasWNHge8DAEBRwJ5GALgNzZw5U2FhYZKka9euydvbW0OGDNGjjz5qvyYwMFD33nuvpD+WcCYmJmrt2rXy8PDQXXfdpSlTpig0NFTjxo3T+vXr1apVKw0dOlSS9MILL+irr77K9d5RUVHq0aOHBgwYIOmPBqpkyZJKTU1V2bJlVaJECVWpUkWStGLFCs2cOVMBAQGSpNmzZ6tdu3b65ptvVLt2be3fv19fffWVatSooQYNGujw4cPasmWL4fd+5JFHNGbMGF29elWlS5fWrl27JEkPPPCALl68qLFjx2rYsGEymUyqXbu2unTpooMHDxb49xsZGal+/frpkUcekSQ9+eST+uGHH/T+++9r6tSp+uWXX9SpUyfVrFlTtWvX1ttvv61atWoV+D4AABQFNI0AcBuaMGGCunTpIkny8vJSlSpVVKJECYdratasaf/z8ePHdfHiRbVs2dI+lp2drWvXrun333/X8ePH1bhxY/u5kiVLOvz8v06ePKn+/fvbfzabzZoyZUqO665cuaJz587p2WeflYfH/y18uXbtmk6dOqWMjAxVqFBBNWrUsJ9r1qxZnk1jQECAypYtq507d6pbt27asmWLunbtqpIlS6pKlSrq2bOnVq1apaNHjyo+Pl4//fSTvXEuiOPHj+vzzz9XVFSUfez69etq166dJCk4OFgLFy5UVFSUAgMD9dhjj9kbZQAAihuaRgC4Dfn6+qpOnTp5XuPl5WX/c2Zmpu666y698cYbOa778wE3Nz7E5s/9kTfy9Mzf/7T8uSfy3//+t+rVq+dwrnz58tq9e3e+7/mnEiVKqFu3btq2bZs6deqk7du3a+nSpZL+2B/5+OOPy8/PT/fff7/69eunr7/+WrGxsTnmMZlMOcYyMzPt3y0rK0ujRo3K8SRab29vSdLo0aPVvXt3bd++XV9++aWGDBmisLAw9e3bN8/6AQAoitjTCABQvXr1lJiYqEqVKqlOnTqqU6eOzp49q8WLF8tkMqlBgwY6dOiQ/frs7GwdO3Ys17nq1KnjcC4rK0sdO3ZUTEyMQzNWrlw5+fr6Kjk52X7P6tWr67XXXtPJkyfVsGFDpaam2vcJStLRo0dv+l169OihHTt2aNeuXSpdurRat24t6Y8H15QvX14REREaMmSIWrVqpYSEhFyf6Ppnc5qWlmYfO3v2rMPv6+zZs/a669Spo6ioKO3cuVMZGRl66aWXZDabNWzYML333nvq16+f/vvf/960dgAAiiKaRgCA2rVrp5o1a+pf//qXfvrpJ+3du1cvvPCCSpUqpRIlSqhfv346fPiw3nzzTZ04cULz5s1zeMrp/xo8eLA+/fRTffTRRzp9+rTmzp0rm80mPz8/lSpVSqmpqTp16pQyMzM1dOhQLVq0SF9++aVOnTql559/Xvv27dNdd92l+vXrq02bNpo2bZqOHTum7du3a/Xq1Tf9Li1atFCFChX0+uuvKygoyN6oVqhQQYmJidq9e7cSEhK0fPlybd26VVarNcccDRo0kLe3t5YtW6aEhAStWLFCR44csZ8fOnSoNm/erHfffVdnzpzRqlWrtGrVKtWtW1deXl7at2+fwsLCdOLECR06dEh79+5VkyZNCvlvBwAA96JpBACoRIkSevPNN5Wdna1+/fpp/PjxevDBB/X8889L+iM9fPPNN7Vp0yb17NlTycnJevDBB3Odq3Xr1po5c6aWLl2qRx99VEePHtWyZcvk7e2tf/zjH6pTp44eeeQRHT16VCNGjFCfPn00Y8YM9ezZU4mJiYqMjFT58uUlSa+//roqVqyo/v37a+HChRo8eHC+vs/DDz+so0eP2h9UI0ndu3fXo48+qgkTJujxxx9XdHS0pkyZouPHj+doHH18fBQWFqZNmzapR48eOnbsmAYNGmQ/36JFC7366qv6z3/+o6CgIH344YdasGCBPdV8/fXXlZ6erj59+mjEiBFq1aqVxo4dm/9/IQAAFCEmmyvftAwAAAAAKNZIGgEAAAAAhmgaAQAAAACGaBoBAAAAAIZoGgEAAAAAhmgaAQAAAACGaBoBAAAAAIZoGgEAAAAAhmgaAQAAAACGaBoBAAAAAIZoGgEAAAAAhmgaAQAAAACG/h9KX5UI0OElUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm1=confusion_matrix(Y_val,y_pred)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Confusion Matrix\")\n",
    "sns.heatmap(cm1, annot=True,fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel(\"Actual Values\")\n",
    "plt.xlabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(\"ukbiobank_variantsonlytraindata_eid.csv\")\n",
    "y_train.to_csv(\"ukbiobank_variantsonlytrainy_eid.csv\")\n",
    "x_test.to_csv(\"ukbiobank_variantsonlytestdata_eid.csv\")\n",
    "y_test.to_csv(\"ukbiobank_variantsonlytesty_eid.csv\")\n",
    "X_val.to_csv(\"ppmi_variantsonlyvaldata_eid.csv\")\n",
    "Y_val.to_csv(\"ppmi_variantsonlyvaly_eid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
