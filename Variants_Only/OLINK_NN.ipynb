{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc5146ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30faba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trn_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63dfa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trn_input = pd.read_pickle(\"/home/ffc4001/ukbiobankdata/Data/final_X_trainolink\")\n",
    "Test_input = pd.read_pickle(\"/home/ffc4001/ukbiobankdata/Data/final_X_testolink\")\n",
    "Trn_target = pd.read_pickle(\"/home/ffc4001/ukbiobankdata/Data/final_Y_trainolink\")\n",
    "Test_target = pd.read_pickle(\"/home/ffc4001/ukbiobankdata/Data/final_Y_testolink\")\n",
    "x_val =pd.read_pickle(\"/home/ffc4001/ukbiobankdata/Data/final_updated_X_valolink\")\n",
    "Y_val =pd.read_pickle(\"/home/ffc4001/ukbiobankdata/Data/final_updated_Y_valolink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df3bd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP THE OLINK DATA FOR ABLATION TEST\n",
    "Trn_input = Trn_input.iloc[:,:543]\n",
    "Test_input = Test_input.iloc[:,:543]\n",
    "x_val =x_val.iloc[:,:543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ed8d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = pd.concat([Trn_input, pd.DataFrame(Trn_target)], axis=1)\n",
    "Test_data = pd.concat([Test_input, pd.DataFrame(Test_target)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0bdbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.concat([x_val, pd.DataFrame(Y_val)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38669c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large Batch Size due to few cases, don't want batches with no cases\n",
    "BATCH_SIZE_1 = 100000\n",
    "BATCH_SIZE_2 = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3ae65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariantsDataset(Dataset):\n",
    "    \"\"\"Variants.\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = torch.FloatTensor(data.values.astype('float'))\n",
    "        print(self.data.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.data[index][-1]\n",
    "        data_val = self.data[index] [:-1]\n",
    "        return data_val,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80bfb730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26073, 544])\n",
      "torch.Size([17335, 544])\n"
     ]
    }
   ],
   "source": [
    "# training and Test dataset \n",
    "train_dataset = VariantsDataset(Train_data)\n",
    "test_dataset = VariantsDataset(Test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a267386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 45, 'pin_memory': True} \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_1, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_2, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37634c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f1db3901a90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1db3aaae20>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5517e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural network \n",
    "device =\"cpu\"\n",
    "input_size = 543\n",
    "hidden_size = 120\n",
    "num_classes = 1\n",
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "hidden_size2 = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4f22f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ---------------  Model  ---------------\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size2, num_classes):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "        self.lrelu1 = nn.LeakyReLU()\n",
    "        self.lrelu2 = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.lrelu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        #out = self.lrelu2(out)\n",
    "        #out = self.dropout2(out)\n",
    "        #out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ed57951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,train_loader,optimizer):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    loss_total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in train_loader:\n",
    "        \n",
    "        #LOADING THE DATA IN A BATCH\n",
    "        data, target = i\n",
    "        #print(target)\n",
    "        #print(data)\n",
    "        # moving the tensors to the configured device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "       \n",
    "        #FORWARD PASS\n",
    "        target = target.float()\n",
    "        output = model(data.float())\n",
    "        #print(output)\n",
    "        #print(target)\n",
    "        loss = criterion(output, target.unsqueeze(1)) \n",
    "        \n",
    "        loss_total += loss\n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        #PREDICTIONS BCELogitsloss()\n",
    "        pred = np.round(torch.sigmoid(output.detach()))\n",
    "        target = target.float()\n",
    "        y_true.extend(target.tolist()) \n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "\n",
    "    print(\"AUC on training set is\" , roc_auc_score(y_true,torch.sigmoid(output.detach())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffa1cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            #data,target = i\n",
    "            #print(target)\n",
    "            #print(data)\n",
    "            # moving the tensors to the configured device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            \n",
    "            output = model(data.float())\n",
    "            \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(torch.sigmoid(output))\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "            \n",
    "    #print(torch.sigmoid(output))        \n",
    "    print(\"AUC on test set is\" , roc_auc_score(y_true,torch.sigmoid(output)))\n",
    "    #print(\"********************************************************\")\n",
    "    print(sum(y_true))\n",
    "    print(sum(y_pred))\n",
    "    cm=confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"Sensitivity on test set is\" , tp/(tp+fn))\n",
    "    print(\"Specificity on test set is\" , tn/(tn+fp)) \n",
    "    if epoch % 20 == 0:\n",
    "        #roc_curve(y_test, classifier.predict_proba(x_test)[:,1])\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true, torch.sigmoid(output))\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Ridge Regression')\n",
    "        display.plot()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f25bd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight  = torch.tensor(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6e1a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss and optimize\n",
    "model = LinearModel(input_size, hidden_size, hidden_size2, num_classes).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n"
   ]
  },
 {
   "cell_type": "code",
   "id": "b0f014d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T12:53:35.388092Z",
     "start_time": "2024-11-19T12:53:35.225860Z"
    }
   },
   "source": [
    "for epoch in range(num_epochs):\n",
    "        train(model,device,train_loader,optimizer)\n",
    "        test(model,device,test_loader)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[43mnum_epochs\u001B[49m):\n\u001B[1;32m      2\u001B[0m         train(model,device,train_loader,optimizer)\n\u001B[1;32m      3\u001B[0m         test(model,device,test_loader)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'num_epochs' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44086d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e16d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC Curve, Sensitivity and specificity and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07468a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#External validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07630ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.concat([x_val, pd.DataFrame(Y_val)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36a48879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([103, 544])\n"
     ]
    }
   ],
   "source": [
    "val_dataset = VariantsDataset(val_data)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_2, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dffb95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, device, val_loader):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            #data,target = i\n",
    "            #print(target)\n",
    "            #print(data)\n",
    "            # moving the tensors to the configured device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            \n",
    "            output = model(data.float())\n",
    "            \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(torch.sigmoid(output))\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "            \n",
    "    #print(torch.sigmoid(output))        \n",
    "    print(\"AUC on test set is\" , roc_auc_score(y_true,torch.sigmoid(output)))\n",
    "    #print(\"********************************************************\")\n",
    "    print(sum(y_true))\n",
    "    print(sum(y_pred))\n",
    "    cm=confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"Sensitivity on test set is\" , tp/(tp+fn))\n",
    "    print(\"Specificity on test set is\" , tn/(tn+fp)) \n",
    "    if epoch % 20 == 0:\n",
    "        #roc_curve(y_test, classifier.predict_proba(x_test)[:,1])\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true, torch.sigmoid(output))\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Ridge Regression')\n",
    "        display.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56aa784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test set is 0.5094905094905096\n",
      "26.0\n",
      "35.0\n",
      "Sensitivity on test set is 0.34615384615384615\n",
      "Specificity on test set is 0.6623376623376623\n"
     ]
    }
   ],
   "source": [
    "test(model,device,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbee3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f752d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"/home/ffc4001/ukbiobankdata/Data/finalvariantnnmodel1.pickle\")\n",
    "#torch.save(model, \"/home/ffc4001/ukbiobankdata/Data/finalvariantnnmodel1.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
